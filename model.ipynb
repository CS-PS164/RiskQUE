{"cells":[{"cell_type":"code","metadata":{"source_hash":"3939019d","execution_start":1686315123305,"execution_millis":4508,"deepnote_to_be_reexecuted":false,"cell_id":"2d622e98b85a4cb5ba52f54fde3d33ab","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers","execution_count":1,"outputs":[{"name":"stderr","text":"2023-06-09 12:52:04.772417: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2023-06-09 12:52:04.774683: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-06-09 12:52:04.811885: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-06-09 12:52:04.812541: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-06-09 12:52:05.631396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"4f3a7a86","execution_start":1686315127806,"execution_millis":99,"sql_integration_id":"deepnote-dataframe-sql","deepnote_variable_name":"df_1","deepnote_to_be_reexecuted":false,"cell_id":"52ca261185e44afeb0e91752b65b3685","deepnote_cell_type":"sql","deepnote_sql_source":"SELECT *\nFROM 'data - AXA_Edited.csv'"},"source":"df_1 = _deepnote_execute_sql('SELECT *\\nFROM \\'data - AXA_Edited.csv\\'', 'SQL_DEEPNOTE_DATAFRAME_SQL', audit_sql_comment='', sql_cache_mode='cache_disabled')\ndf_1","execution_count":2,"outputs":[{"data":{"application/vnd.deepnote.sql-output-metadata+json":{"status":"success_no_cache","size_in_bytes":13910}},"metadata":{},"output_type":"display_data"},{"output_type":"execute_result","execution_count":2,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":14,"row_count":40,"columns":[{"name":"Tanggal","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"Januari 2023","count":10},{"name":"Februari 2023","count":10},{"name":"2 others","count":20}]}},{"name":"DPLK","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"FFS PPIP-MICK","count":4},{"name":"FFS PPIP-MICK2","count":4},{"name":"8 others","count":32}]}},{"name":"Merek","dtype":"object","stats":{"unique_count":1,"nan_count":0,"categories":[{"name":"AXA","count":40}]}},{"name":"Tipe Risiko","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"Agresif","count":16},{"name":"Konservatif","count":16},{"name":"Moderat","count":8}]}},{"name":"Saham","dtype":"float64","stats":{"unique_count":17,"nan_count":0,"min":"0.0","max":"94.72","histogram":[{"bin_start":0,"bin_end":9.472,"count":24},{"bin_start":9.472,"bin_end":18.944,"count":0},{"bin_start":18.944,"bin_end":28.415999999999997,"count":2},{"bin_start":28.415999999999997,"bin_end":37.888,"count":2},{"bin_start":37.888,"bin_end":47.36,"count":4},{"bin_start":47.36,"bin_end":56.831999999999994,"count":0},{"bin_start":56.831999999999994,"bin_end":66.304,"count":0},{"bin_start":66.304,"bin_end":75.776,"count":0},{"bin_start":75.776,"bin_end":85.24799999999999,"count":0},{"bin_start":85.24799999999999,"bin_end":94.72,"count":8}]}},{"name":"Pasar Uang / Kas","dtype":"float64","stats":{"unique_count":25,"nan_count":0,"min":"2.61","max":"100.0","histogram":[{"bin_start":2.61,"bin_end":12.349,"count":12},{"bin_start":12.349,"bin_end":22.088,"count":7},{"bin_start":22.088,"bin_end":31.827,"count":3},{"bin_start":31.827,"bin_end":41.566,"count":2},{"bin_start":41.566,"bin_end":51.30500000000001,"count":0},{"bin_start":51.30500000000001,"bin_end":61.044000000000004,"count":0},{"bin_start":61.044000000000004,"bin_end":70.783,"count":0},{"bin_start":70.783,"bin_end":80.522,"count":0},{"bin_start":80.522,"bin_end":90.26100000000001,"count":0},{"bin_start":90.26100000000001,"bin_end":100,"count":16}]}},{"name":"Pendapatan Tetap (Obligasi / SBN / Sukuk)","dtype":"float64","stats":{"unique_count":21,"nan_count":0,"min":"0.0","max":"97.39","histogram":[{"bin_start":0,"bin_end":9.739,"count":24},{"bin_start":9.739,"bin_end":19.478,"count":0},{"bin_start":19.478,"bin_end":29.217000000000002,"count":0},{"bin_start":29.217000000000002,"bin_end":38.956,"count":1},{"bin_start":38.956,"bin_end":48.69500000000001,"count":7},{"bin_start":48.69500000000001,"bin_end":58.434000000000005,"count":0},{"bin_start":58.434000000000005,"bin_end":68.173,"count":0},{"bin_start":68.173,"bin_end":77.912,"count":0},{"bin_start":77.912,"bin_end":87.65100000000001,"count":4},{"bin_start":87.65100000000001,"bin_end":97.39,"count":4}]}},{"name":"1 Bulan","dtype":"float64","stats":{"unique_count":33,"nan_count":0,"min":"0.01","max":"1.89","histogram":[{"bin_start":0.01,"bin_end":0.198,"count":4},{"bin_start":0.198,"bin_end":0.386,"count":5},{"bin_start":0.386,"bin_end":0.5740000000000001,"count":16},{"bin_start":0.5740000000000001,"bin_end":0.762,"count":2},{"bin_start":0.762,"bin_end":0.95,"count":1},{"bin_start":0.95,"bin_end":1.1380000000000001,"count":7},{"bin_start":1.1380000000000001,"bin_end":1.326,"count":2},{"bin_start":1.326,"bin_end":1.514,"count":0},{"bin_start":1.514,"bin_end":1.702,"count":2},{"bin_start":1.702,"bin_end":1.89,"count":1}]}},{"name":"3 Bulan","dtype":"float64","stats":{"unique_count":36,"nan_count":0,"min":"-2.47","max":"6.37","histogram":[{"bin_start":-2.47,"bin_end":-1.5860000000000003,"count":4},{"bin_start":-1.5860000000000003,"bin_end":-0.7020000000000002,"count":0},{"bin_start":-0.7020000000000002,"bin_end":0.18199999999999994,"count":0},{"bin_start":0.18199999999999994,"bin_end":1.0659999999999998,"count":2},{"bin_start":1.0659999999999998,"bin_end":1.9499999999999997,"count":23},{"bin_start":1.9499999999999997,"bin_end":2.834,"count":8},{"bin_start":2.834,"bin_end":3.7179999999999995,"count":1},{"bin_start":3.7179999999999995,"bin_end":4.602,"count":1},{"bin_start":4.602,"bin_end":5.486000000000001,"count":0},{"bin_start":5.486000000000001,"bin_end":6.37,"count":1}]}},{"name":"6 Bulan","dtype":"float64","stats":{"unique_count":38,"nan_count":0,"min":"-0.56","max":"8.66","histogram":[{"bin_start":-0.56,"bin_end":0.362,"count":6},{"bin_start":0.362,"bin_end":1.284,"count":0},{"bin_start":1.284,"bin_end":2.206,"count":8},{"bin_start":2.206,"bin_end":3.128,"count":14},{"bin_start":3.128,"bin_end":4.050000000000001,"count":5},{"bin_start":4.050000000000001,"bin_end":4.9719999999999995,"count":3},{"bin_start":4.9719999999999995,"bin_end":5.894,"count":1},{"bin_start":5.894,"bin_end":6.816000000000001,"count":1},{"bin_start":6.816000000000001,"bin_end":7.7379999999999995,"count":1},{"bin_start":7.7379999999999995,"bin_end":8.66,"count":1}]}},{"name":"1 Tahun","dtype":"float64","stats":{"unique_count":38,"nan_count":0,"min":"-2.27","max":"10.64","histogram":[{"bin_start":-2.27,"bin_end":-0.9790000000000001,"count":2},{"bin_start":-0.9790000000000001,"bin_end":0.31199999999999983,"count":0},{"bin_start":0.31199999999999983,"bin_end":1.6029999999999998,"count":2},{"bin_start":1.6029999999999998,"bin_end":2.8939999999999997,"count":0},{"bin_start":2.8939999999999997,"bin_end":4.1850000000000005,"count":8},{"bin_start":4.1850000000000005,"bin_end":5.475999999999999,"count":14},{"bin_start":5.475999999999999,"bin_end":6.7669999999999995,"count":5},{"bin_start":6.7669999999999995,"bin_end":8.058,"count":4},{"bin_start":8.058,"bin_end":9.349,"count":4},{"bin_start":9.349,"bin_end":10.64,"count":1}]}},{"name":"3 Tahun","dtype":"float64","stats":{"unique_count":38,"nan_count":0,"min":"13.88","max":"46.49","histogram":[{"bin_start":13.88,"bin_end":17.141000000000002,"count":21},{"bin_start":17.141000000000002,"bin_end":20.402,"count":1},{"bin_start":20.402,"bin_end":23.663000000000004,"count":1},{"bin_start":23.663000000000004,"bin_end":26.924,"count":5},{"bin_start":26.924,"bin_end":30.185000000000002,"count":2},{"bin_start":30.185000000000002,"bin_end":33.446000000000005,"count":2},{"bin_start":33.446000000000005,"bin_end":36.707,"count":4},{"bin_start":36.707,"bin_end":39.968,"count":0},{"bin_start":39.968,"bin_end":43.229,"count":0},{"bin_start":43.229,"bin_end":46.49,"count":4}]}},{"name":"5 Tahun","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"6.45","max":"51.22","histogram":[{"bin_start":6.45,"bin_end":10.927,"count":4},{"bin_start":10.927,"bin_end":15.404,"count":1},{"bin_start":15.404,"bin_end":19.880999999999997,"count":2},{"bin_start":19.880999999999997,"bin_end":24.357999999999997,"count":1},{"bin_start":24.357999999999997,"bin_end":28.834999999999997,"count":5},{"bin_start":28.834999999999997,"bin_end":33.312,"count":7},{"bin_start":33.312,"bin_end":37.788999999999994,"count":12},{"bin_start":37.788999999999994,"bin_end":42.266,"count":0},{"bin_start":42.266,"bin_end":46.742999999999995,"count":0},{"bin_start":46.742999999999995,"bin_end":51.22,"count":8}]}},{"name":"AUM (M)","dtype":"float64","stats":{"unique_count":39,"nan_count":0,"min":"7.77","max":"1124.1","histogram":[{"bin_start":7.77,"bin_end":119.40299999999999,"count":28},{"bin_start":119.40299999999999,"bin_end":231.036,"count":4},{"bin_start":231.036,"bin_end":342.669,"count":0},{"bin_start":342.669,"bin_end":454.30199999999996,"count":4},{"bin_start":454.30199999999996,"bin_end":565.935,"count":0},{"bin_start":565.935,"bin_end":677.568,"count":0},{"bin_start":677.568,"bin_end":789.2009999999999,"count":0},{"bin_start":789.2009999999999,"bin_end":900.834,"count":0},{"bin_start":900.834,"bin_end":1012.467,"count":0},{"bin_start":1012.467,"bin_end":1124.1,"count":4}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"Tanggal":"Januari 2023","DPLK":"FFS PPIP-MICK","Merek":"AXA","Tipe Risiko":"Agresif","Saham":28.52,"Pasar Uang / Kas":27.74,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":43.75,"1 Bulan":1.08,"3 Bulan":1.96,"6 Bulan":3.47,"1 Tahun":6.38,"3 Tahun":14.88,"5 Tahun":26.62,"AUM (M)":8.1,"_deepnote_index_column":0},{"Tanggal":"Februari 2023","DPLK":"FFS PPIP-MICK","Merek":"AXA","Tipe Risiko":"Agresif","Saham":29.79,"Pasar Uang / Kas":31.12,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":39.09,"1 Bulan":0.08,"3 Bulan":0.57,"6 Bulan":2.05,"1 Tahun":5.94,"3 Tahun":17.08,"5 Tahun":26.44,"AUM (M)":7.77,"_deepnote_index_column":1},{"Tanggal":"Maret 2023","DPLK":"FFS PPIP-MICK","Merek":"AXA","Tipe Risiko":"Agresif","Saham":27.79,"Pasar Uang / Kas":34.34,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":37.87,"1 Bulan":0.56,"3 Bulan":1.73,"6 Bulan":2.99,"1 Tahun":4.03,"3 Tahun":26.99,"5 Tahun":28.19,"AUM (M)":8.36,"_deepnote_index_column":2},{"Tanggal":"April 2023","DPLK":"FFS PPIP-MICK","Merek":"AXA","Tipe Risiko":"Agresif","Saham":27.93,"Pasar Uang / Kas":33.04,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":39.03,"1 Bulan":0.98,"3 Bulan":1.63,"6 Bulan":3.62,"1 Tahun":3.47,"3 Tahun":27.39,"5 Tahun":30.12,"AUM (M)":8.46,"_deepnote_index_column":3},{"Tanggal":"Januari 2023","DPLK":"FFS PPIP-MICK2","Merek":"AXA","Tipe Risiko":"Agresif","Saham":37.96,"Pasar Uang / Kas":22.28,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":39.76,"1 Bulan":1.17,"3 Bulan":1.62,"6 Bulan":3.53,"1 Tahun":6.4,"3 Tahun":16.56,"5 Tahun":26.97,"AUM (M)":48.37,"_deepnote_index_column":4},{"Tanggal":"Februari 2023","DPLK":"FFS PPIP-MICK2","Merek":"AXA","Tipe Risiko":"Agresif","Saham":38.67,"Pasar Uang / Kas":19.86,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":41.47,"1 Bulan":0.14,"3 Bulan":0.19,"6 Bulan":1.6,"1 Tahun":5.47,"3 Tahun":19.98,"5 Tahun":27.17,"AUM (M)":48.37,"_deepnote_index_column":5},{"Tanggal":"Maret 2023","DPLK":"FFS PPIP-MICK2","Merek":"AXA","Tipe Risiko":"Agresif","Saham":38.03,"Pasar Uang / Kas":20.99,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":40.98,"1 Bulan":0.77,"3 Bulan":2.09,"6 Bulan":2.96,"1 Tahun":3.41,"3 Tahun":33.68,"5 Tahun":31,"AUM (M)":49.41,"_deepnote_index_column":6},{"Tanggal":"April 2023","DPLK":"FFS PPIP-MICK2","Merek":"AXA","Tipe Risiko":"Agresif","Saham":38,"Pasar Uang / Kas":20.08,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":41.92,"1 Bulan":1.16,"3 Bulan":2.08,"6 Bulan":3.73,"1 Tahun":2.94,"3 Tahun":33.58,"5 Tahun":33.85,"AUM (M)":50.37,"_deepnote_index_column":7},{"Tanggal":"Januari 2023","DPLK":"FFS PPIP-PT","Merek":"AXA","Tipe Risiko":"Moderat","Saham":0,"Pasar Uang / Kas":2.61,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":97.39,"1 Bulan":1.89,"3 Bulan":6.37,"6 Bulan":6.74,"1 Tahun":8.38,"3 Tahun":25.31,"5 Tahun":47.7,"AUM (M)":190.69,"_deepnote_index_column":8},{"Tanggal":"Februari 2023","DPLK":"FFS PPIP-PT","Merek":"AXA","Tipe Risiko":"Moderat","Saham":0,"Pasar Uang / Kas":3.12,"Pendapatan Tetap (Obligasi / SBN / Sukuk)":96.88,"1 Bulan":0.03,"3 Bulan":2.63,"6 Bulan":4.81,"1 Tahun":7.22,"3 Tahun":26.52,"5 Tahun":48.6,"AUM (M)":191.05,"_deepnote_index_column":9}]},"text/plain":"          Tanggal                 DPLK Merek  Tipe Risiko  Saham  \\\n0    Januari 2023        FFS PPIP-MICK   AXA      Agresif  28.52   \n1   Februari 2023        FFS PPIP-MICK   AXA      Agresif  29.79   \n2      Maret 2023        FFS PPIP-MICK   AXA      Agresif  27.79   \n3      April 2023        FFS PPIP-MICK   AXA      Agresif  27.93   \n4    Januari 2023       FFS PPIP-MICK2   AXA      Agresif  37.96   \n5   Februari 2023       FFS PPIP-MICK2   AXA      Agresif  38.67   \n6      Maret 2023       FFS PPIP-MICK2   AXA      Agresif  38.03   \n7      April 2023       FFS PPIP-MICK2   AXA      Agresif  38.00   \n8    Januari 2023          FFS PPIP-PT   AXA      Moderat   0.00   \n9   Februari 2023          FFS PPIP-PT   AXA      Moderat   0.00   \n10     Maret 2023          FFS PPIP-PT   AXA      Moderat   0.00   \n11     April 2023          FFS PPIP-PT   AXA      Moderat   0.00   \n12   Januari 2023          FFS PPIP-PU   AXA  Konservatif   0.00   \n13  Februari 2023          FFS PPIP-PU   AXA  Konservatif   0.00   \n14     Maret 2023          FFS PPIP-PU   AXA  Konservatif   0.00   \n15     April 2023          FFS PPIP-PU   AXA  Konservatif   0.00   \n16   Januari 2023    FFS PPIP-PU-SMILE   AXA  Konservatif   0.00   \n17  Februari 2023    FFS PPIP-PU-SMILE   AXA  Konservatif   0.00   \n18     Maret 2023    FFS PPIP-PU-SMILE   AXA  Konservatif   0.00   \n19     April 2023    FFS PPIP-PU-SMILE   AXA  Konservatif   0.00   \n20   Januari 2023        FFS PPIP-SHPT   AXA      Agresif  87.50   \n21  Februari 2023        FFS PPIP-SHPT   AXA      Agresif  88.20   \n22     Maret 2023        FFS PPIP-SHPT   AXA      Agresif  87.53   \n23     April 2023        FFS PPIP-SHPT   AXA      Agresif  87.49   \n24   Januari 2023        FFS PPIP-SHPU   AXA      Agresif  94.72   \n25  Februari 2023        FFS PPIP-SHPU   AXA      Agresif  94.31   \n26     Maret 2023        FFS PPIP-SHPU   AXA      Agresif  94.51   \n27     April 2023        FFS PPIP-SHPU   AXA      Agresif  94.58   \n28   Januari 2023        FFS PPIP-SYPT   AXA      Moderat   0.00   \n29  Februari 2023        FFS PPIP-SYPT   AXA      Moderat   0.00   \n30     Maret 2023        FFS PPIP-SYPT   AXA      Moderat   0.00   \n31     April 2023        FFS PPIP-SYPT   AXA      Moderat   0.00   \n32   Januari 2023        FFS PPIP-SYPU   AXA  Konservatif   0.00   \n33  Februari 2023        FFS PPIP-SYPU   AXA  Konservatif   0.00   \n34     Maret 2023        FFS PPIP-SYPU   AXA  Konservatif   0.00   \n35     April 2023        FFS PPIP-SYPU   AXA  Konservatif   0.00   \n36   Januari 2023  FFS PPIP-SYPU-SMILE   AXA  Konservatif   0.00   \n37  Februari 2023  FFS PPIP-SYPU-SMILE   AXA  Konservatif   0.00   \n38     Maret 2023  FFS PPIP-SYPU-SMILE   AXA  Konservatif   0.00   \n39     April 2023  FFS PPIP-SYPU-SMILE   AXA  Konservatif   0.00   \n\n    Pasar Uang / Kas  Pendapatan Tetap (Obligasi / SBN / Sukuk)  1 Bulan  \\\n0              27.74                                      43.75     1.08   \n1              31.12                                      39.09     0.08   \n2              34.34                                      37.87     0.56   \n3              33.04                                      39.03     0.98   \n4              22.28                                      39.76     1.17   \n5              19.86                                      41.47     0.14   \n6              20.99                                      40.98     0.77   \n7              20.08                                      41.92     1.16   \n8               2.61                                      97.39     1.89   \n9               3.12                                      96.88     0.03   \n10              5.04                                      94.96     1.04   \n11              5.08                                      94.92     1.07   \n12            100.00                                       0.00     0.48   \n13            100.00                                       0.00     0.43   \n14            100.00                                       0.00     0.49   \n15            100.00                                       0.00     0.38   \n16            100.00                                       0.00     0.47   \n17            100.00                                       0.00     0.43   \n18            100.00                                       0.00     0.49   \n19            100.00                                       0.00     0.35   \n20              5.73                                       6.77     1.01   \n21              5.33                                       6.48     0.22   \n22              5.75                                       6.72     0.42   \n23              4.96                                       7.55     1.54   \n24              5.28                                       0.00     0.96   \n25              5.69                                       0.00     0.22   \n26              5.49                                       0.00     0.37   \n27              5.42                                       0.00     1.61   \n28             14.49                                      85.51     1.05   \n29             14.46                                      85.54     0.01   \n30             14.60                                      85.40     0.72   \n31             15.22                                      84.78     0.68   \n32            100.00                                       0.00     0.43   \n33            100.00                                       0.00     0.43   \n34            100.00                                       0.00     0.47   \n35            100.00                                       0.00     0.42   \n36            100.00                                       0.00     0.45   \n37            100.00                                       0.00     0.41   \n38            100.00                                       0.00     0.44   \n39            100.00                                       0.00     0.40   \n\n    3 Bulan  6 Bulan  1 Tahun  3 Tahun  5 Tahun  AUM (M)  \n0      1.96     3.47     6.38    14.88    26.62     8.10  \n1      0.57     2.05     5.94    17.08    26.44     7.77  \n2      1.73     2.99     4.03    26.99    28.19     8.36  \n3      1.63     3.62     3.47    27.39    30.12     8.46  \n4      1.62     3.53     6.40    16.56    26.97    48.37  \n5      0.19     1.60     5.47    19.98    27.17    48.37  \n6      2.09     2.96     3.41    33.68    31.00    49.41  \n7      2.08     3.73     2.94    33.58    33.85    50.37  \n8      6.37     6.74     8.38    25.31    47.70   190.69  \n9      2.63     4.81     7.22    26.52    48.60   191.05  \n10     2.98     7.10     9.27    36.16    49.56   194.24  \n11     2.15     8.66    10.64    35.61    51.22   198.99  \n12     1.23     2.11     4.33    16.58    36.77   445.75  \n13     1.29     2.24     4.42    16.41    36.56   433.72  \n14     1.41     2.52     4.55    16.29    36.41   440.22  \n15     1.30     2.55     4.68    16.06    36.04   428.25  \n16     1.23     2.07     4.39    16.23    35.88    89.78  \n17     1.29     2.21     4.49    16.06    35.67    90.16  \n18     1.40     2.51     4.60    16.00    35.55    90.37  \n19     1.28     2.52     4.69    15.83    35.16    90.61  \n20    -1.80     2.77     8.71    16.56     9.11    43.15  \n21    -1.72    -0.08     7.47    23.97    10.04    44.04  \n22     1.66     0.36     1.09    46.49    16.56    44.54  \n23     2.19     0.35    -1.43    44.84    20.97    45.30  \n24    -2.47     2.38     8.95    15.18     6.45    46.03  \n25    -2.13    -0.56     7.61    22.78     7.23    46.65  \n26     1.56    -0.26     0.56    46.23    14.45    47.05  \n27     2.21    -0.31    -2.27    44.75    19.31    48.34  \n28     3.90     4.59     5.91    25.50    47.57  1115.09  \n29     1.97     3.23     5.20    25.39    47.35  1110.88  \n30     1.78     4.32     5.98    31.93    47.65  1117.36  \n31     1.41     5.37     6.80    31.00    49.25  1124.10  \n32     1.18     2.02     4.24    15.32    33.58    69.90  \n33     1.24     2.16     4.39    15.20    33.43    70.13  \n34     1.33     2.39     4.40    15.09    33.34    70.42  \n35     1.32     2.52     4.54    14.95    33.10    70.93  \n36     1.14     1.94     3.51    14.43    32.45    18.09  \n37     1.26     2.08     3.71    14.26    32.29    18.17  \n38     1.31     2.28     3.84    14.07    32.17    18.25  \n39     1.26     2.41     4.03    13.88    31.93    18.35  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tanggal</th>\n      <th>DPLK</th>\n      <th>Merek</th>\n      <th>Tipe Risiko</th>\n      <th>Saham</th>\n      <th>Pasar Uang / Kas</th>\n      <th>Pendapatan Tetap (Obligasi / SBN / Sukuk)</th>\n      <th>1 Bulan</th>\n      <th>3 Bulan</th>\n      <th>6 Bulan</th>\n      <th>1 Tahun</th>\n      <th>3 Tahun</th>\n      <th>5 Tahun</th>\n      <th>AUM (M)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-MICK</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>28.52</td>\n      <td>27.74</td>\n      <td>43.75</td>\n      <td>1.08</td>\n      <td>1.96</td>\n      <td>3.47</td>\n      <td>6.38</td>\n      <td>14.88</td>\n      <td>26.62</td>\n      <td>8.10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-MICK</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>29.79</td>\n      <td>31.12</td>\n      <td>39.09</td>\n      <td>0.08</td>\n      <td>0.57</td>\n      <td>2.05</td>\n      <td>5.94</td>\n      <td>17.08</td>\n      <td>26.44</td>\n      <td>7.77</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-MICK</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>27.79</td>\n      <td>34.34</td>\n      <td>37.87</td>\n      <td>0.56</td>\n      <td>1.73</td>\n      <td>2.99</td>\n      <td>4.03</td>\n      <td>26.99</td>\n      <td>28.19</td>\n      <td>8.36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-MICK</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>27.93</td>\n      <td>33.04</td>\n      <td>39.03</td>\n      <td>0.98</td>\n      <td>1.63</td>\n      <td>3.62</td>\n      <td>3.47</td>\n      <td>27.39</td>\n      <td>30.12</td>\n      <td>8.46</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-MICK2</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>37.96</td>\n      <td>22.28</td>\n      <td>39.76</td>\n      <td>1.17</td>\n      <td>1.62</td>\n      <td>3.53</td>\n      <td>6.40</td>\n      <td>16.56</td>\n      <td>26.97</td>\n      <td>48.37</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-MICK2</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>38.67</td>\n      <td>19.86</td>\n      <td>41.47</td>\n      <td>0.14</td>\n      <td>0.19</td>\n      <td>1.60</td>\n      <td>5.47</td>\n      <td>19.98</td>\n      <td>27.17</td>\n      <td>48.37</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-MICK2</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>38.03</td>\n      <td>20.99</td>\n      <td>40.98</td>\n      <td>0.77</td>\n      <td>2.09</td>\n      <td>2.96</td>\n      <td>3.41</td>\n      <td>33.68</td>\n      <td>31.00</td>\n      <td>49.41</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-MICK2</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>38.00</td>\n      <td>20.08</td>\n      <td>41.92</td>\n      <td>1.16</td>\n      <td>2.08</td>\n      <td>3.73</td>\n      <td>2.94</td>\n      <td>33.58</td>\n      <td>33.85</td>\n      <td>50.37</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-PT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>2.61</td>\n      <td>97.39</td>\n      <td>1.89</td>\n      <td>6.37</td>\n      <td>6.74</td>\n      <td>8.38</td>\n      <td>25.31</td>\n      <td>47.70</td>\n      <td>190.69</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-PT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>3.12</td>\n      <td>96.88</td>\n      <td>0.03</td>\n      <td>2.63</td>\n      <td>4.81</td>\n      <td>7.22</td>\n      <td>26.52</td>\n      <td>48.60</td>\n      <td>191.05</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-PT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>5.04</td>\n      <td>94.96</td>\n      <td>1.04</td>\n      <td>2.98</td>\n      <td>7.10</td>\n      <td>9.27</td>\n      <td>36.16</td>\n      <td>49.56</td>\n      <td>194.24</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-PT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>5.08</td>\n      <td>94.92</td>\n      <td>1.07</td>\n      <td>2.15</td>\n      <td>8.66</td>\n      <td>10.64</td>\n      <td>35.61</td>\n      <td>51.22</td>\n      <td>198.99</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-PU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.48</td>\n      <td>1.23</td>\n      <td>2.11</td>\n      <td>4.33</td>\n      <td>16.58</td>\n      <td>36.77</td>\n      <td>445.75</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-PU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.43</td>\n      <td>1.29</td>\n      <td>2.24</td>\n      <td>4.42</td>\n      <td>16.41</td>\n      <td>36.56</td>\n      <td>433.72</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-PU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.49</td>\n      <td>1.41</td>\n      <td>2.52</td>\n      <td>4.55</td>\n      <td>16.29</td>\n      <td>36.41</td>\n      <td>440.22</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-PU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.38</td>\n      <td>1.30</td>\n      <td>2.55</td>\n      <td>4.68</td>\n      <td>16.06</td>\n      <td>36.04</td>\n      <td>428.25</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-PU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.47</td>\n      <td>1.23</td>\n      <td>2.07</td>\n      <td>4.39</td>\n      <td>16.23</td>\n      <td>35.88</td>\n      <td>89.78</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-PU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.43</td>\n      <td>1.29</td>\n      <td>2.21</td>\n      <td>4.49</td>\n      <td>16.06</td>\n      <td>35.67</td>\n      <td>90.16</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-PU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.49</td>\n      <td>1.40</td>\n      <td>2.51</td>\n      <td>4.60</td>\n      <td>16.00</td>\n      <td>35.55</td>\n      <td>90.37</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-PU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.35</td>\n      <td>1.28</td>\n      <td>2.52</td>\n      <td>4.69</td>\n      <td>15.83</td>\n      <td>35.16</td>\n      <td>90.61</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-SHPT</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>87.50</td>\n      <td>5.73</td>\n      <td>6.77</td>\n      <td>1.01</td>\n      <td>-1.80</td>\n      <td>2.77</td>\n      <td>8.71</td>\n      <td>16.56</td>\n      <td>9.11</td>\n      <td>43.15</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-SHPT</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>88.20</td>\n      <td>5.33</td>\n      <td>6.48</td>\n      <td>0.22</td>\n      <td>-1.72</td>\n      <td>-0.08</td>\n      <td>7.47</td>\n      <td>23.97</td>\n      <td>10.04</td>\n      <td>44.04</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-SHPT</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>87.53</td>\n      <td>5.75</td>\n      <td>6.72</td>\n      <td>0.42</td>\n      <td>1.66</td>\n      <td>0.36</td>\n      <td>1.09</td>\n      <td>46.49</td>\n      <td>16.56</td>\n      <td>44.54</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-SHPT</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>87.49</td>\n      <td>4.96</td>\n      <td>7.55</td>\n      <td>1.54</td>\n      <td>2.19</td>\n      <td>0.35</td>\n      <td>-1.43</td>\n      <td>44.84</td>\n      <td>20.97</td>\n      <td>45.30</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-SHPU</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>94.72</td>\n      <td>5.28</td>\n      <td>0.00</td>\n      <td>0.96</td>\n      <td>-2.47</td>\n      <td>2.38</td>\n      <td>8.95</td>\n      <td>15.18</td>\n      <td>6.45</td>\n      <td>46.03</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-SHPU</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>94.31</td>\n      <td>5.69</td>\n      <td>0.00</td>\n      <td>0.22</td>\n      <td>-2.13</td>\n      <td>-0.56</td>\n      <td>7.61</td>\n      <td>22.78</td>\n      <td>7.23</td>\n      <td>46.65</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-SHPU</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>94.51</td>\n      <td>5.49</td>\n      <td>0.00</td>\n      <td>0.37</td>\n      <td>1.56</td>\n      <td>-0.26</td>\n      <td>0.56</td>\n      <td>46.23</td>\n      <td>14.45</td>\n      <td>47.05</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-SHPU</td>\n      <td>AXA</td>\n      <td>Agresif</td>\n      <td>94.58</td>\n      <td>5.42</td>\n      <td>0.00</td>\n      <td>1.61</td>\n      <td>2.21</td>\n      <td>-0.31</td>\n      <td>-2.27</td>\n      <td>44.75</td>\n      <td>19.31</td>\n      <td>48.34</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-SYPT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>14.49</td>\n      <td>85.51</td>\n      <td>1.05</td>\n      <td>3.90</td>\n      <td>4.59</td>\n      <td>5.91</td>\n      <td>25.50</td>\n      <td>47.57</td>\n      <td>1115.09</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-SYPT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>14.46</td>\n      <td>85.54</td>\n      <td>0.01</td>\n      <td>1.97</td>\n      <td>3.23</td>\n      <td>5.20</td>\n      <td>25.39</td>\n      <td>47.35</td>\n      <td>1110.88</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-SYPT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>14.60</td>\n      <td>85.40</td>\n      <td>0.72</td>\n      <td>1.78</td>\n      <td>4.32</td>\n      <td>5.98</td>\n      <td>31.93</td>\n      <td>47.65</td>\n      <td>1117.36</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-SYPT</td>\n      <td>AXA</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>15.22</td>\n      <td>84.78</td>\n      <td>0.68</td>\n      <td>1.41</td>\n      <td>5.37</td>\n      <td>6.80</td>\n      <td>31.00</td>\n      <td>49.25</td>\n      <td>1124.10</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-SYPU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.43</td>\n      <td>1.18</td>\n      <td>2.02</td>\n      <td>4.24</td>\n      <td>15.32</td>\n      <td>33.58</td>\n      <td>69.90</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-SYPU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.43</td>\n      <td>1.24</td>\n      <td>2.16</td>\n      <td>4.39</td>\n      <td>15.20</td>\n      <td>33.43</td>\n      <td>70.13</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-SYPU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.47</td>\n      <td>1.33</td>\n      <td>2.39</td>\n      <td>4.40</td>\n      <td>15.09</td>\n      <td>33.34</td>\n      <td>70.42</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-SYPU</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>1.32</td>\n      <td>2.52</td>\n      <td>4.54</td>\n      <td>14.95</td>\n      <td>33.10</td>\n      <td>70.93</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Januari 2023</td>\n      <td>FFS PPIP-SYPU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.45</td>\n      <td>1.14</td>\n      <td>1.94</td>\n      <td>3.51</td>\n      <td>14.43</td>\n      <td>32.45</td>\n      <td>18.09</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Februari 2023</td>\n      <td>FFS PPIP-SYPU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.41</td>\n      <td>1.26</td>\n      <td>2.08</td>\n      <td>3.71</td>\n      <td>14.26</td>\n      <td>32.29</td>\n      <td>18.17</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Maret 2023</td>\n      <td>FFS PPIP-SYPU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>1.31</td>\n      <td>2.28</td>\n      <td>3.84</td>\n      <td>14.07</td>\n      <td>32.17</td>\n      <td>18.25</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>April 2023</td>\n      <td>FFS PPIP-SYPU-SMILE</td>\n      <td>AXA</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>0.00</td>\n      <td>0.40</td>\n      <td>1.26</td>\n      <td>2.41</td>\n      <td>4.03</td>\n      <td>13.88</td>\n      <td>31.93</td>\n      <td>18.35</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":"baa4ad08","execution_start":1686315127908,"execution_millis":7,"deepnote_to_be_reexecuted":false,"cell_id":"2655a16f3e964ccb8cbed47b422ff771","deepnote_cell_type":"code"},"source":"# Load the data from CSV file\ndata = pd.read_csv('data - Data_Edited.csv')","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"a1001531","execution_start":1686315127919,"execution_millis":37,"deepnote_to_be_reexecuted":false,"cell_id":"64b9d92af99d4b38bbaf7f9475b57027","deepnote_cell_type":"code"},"source":"data.fillna(0)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":15,"row_count":112,"columns":[{"name":"Tanggal","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"Januari 2023","count":28},{"name":"Februari 2023","count":28},{"name":"2 others","count":56}]}},{"name":"Merek","dtype":"object","stats":{"unique_count":6,"nan_count":0,"categories":[{"name":"Allianz","count":32},{"name":"BNI","count":28},{"name":"4 others","count":52}]}},{"name":"DPLK","dtype":"object","stats":{"unique_count":28,"nan_count":0,"categories":[{"name":"DPLK_Equity_Fund","count":4},{"name":"DPLK_Fixed_Income","count":4},{"name":"26 others","count":104}]}},{"name":"Tipe Risiko","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"Konservatif","count":48},{"name":"Agresif","count":32},{"name":"Moderat","count":32}]}},{"name":"Saham","dtype":"float64","stats":{"unique_count":35,"nan_count":0,"min":"0.0","max":"99.25","histogram":[{"bin_start":0,"bin_end":9.925,"count":80},{"bin_start":9.925,"bin_end":19.85,"count":2},{"bin_start":19.85,"bin_end":29.775000000000002,"count":2},{"bin_start":29.775000000000002,"bin_end":39.7,"count":0},{"bin_start":39.7,"bin_end":49.625,"count":9},{"bin_start":49.625,"bin_end":59.550000000000004,"count":3},{"bin_start":59.550000000000004,"bin_end":69.47500000000001,"count":0},{"bin_start":69.47500000000001,"bin_end":79.4,"count":0},{"bin_start":79.4,"bin_end":89.325,"count":5},{"bin_start":89.325,"bin_end":99.25,"count":11}]}},{"name":"Pasar Uang / Kas","dtype":"float64","stats":{"unique_count":88,"nan_count":0,"min":"0.75","max":"100.0","histogram":[{"bin_start":0.75,"bin_end":10.675,"count":43},{"bin_start":10.675,"bin_end":20.6,"count":8},{"bin_start":20.6,"bin_end":30.525000000000002,"count":4},{"bin_start":30.525000000000002,"bin_end":40.45,"count":5},{"bin_start":40.45,"bin_end":50.375,"count":8},{"bin_start":50.375,"bin_end":60.300000000000004,"count":1},{"bin_start":60.300000000000004,"bin_end":70.22500000000001,"count":7},{"bin_start":70.22500000000001,"bin_end":80.15,"count":2},{"bin_start":80.15,"bin_end":90.075,"count":11},{"bin_start":90.075,"bin_end":100,"count":23}]}},{"name":"Obligasi / SBN / Sukuk","dtype":"float64","stats":{"unique_count":68,"nan_count":0,"min":"0.0","max":"97.98","histogram":[{"bin_start":0,"bin_end":9.798,"count":48},{"bin_start":9.798,"bin_end":19.596,"count":11},{"bin_start":19.596,"bin_end":29.394,"count":1},{"bin_start":29.394,"bin_end":39.192,"count":7},{"bin_start":39.192,"bin_end":48.99,"count":2},{"bin_start":48.99,"bin_end":58.788,"count":7},{"bin_start":58.788,"bin_end":68.586,"count":2},{"bin_start":68.586,"bin_end":78.384,"count":3},{"bin_start":78.384,"bin_end":88.182,"count":3},{"bin_start":88.182,"bin_end":97.98,"count":28}]}},{"name":"Total Invest","dtype":"float64","stats":{"unique_count":7,"nan_count":0,"min":"99.85","max":"101.45","histogram":[{"bin_start":99.85,"bin_end":100.00999999999999,"count":100},{"bin_start":100.00999999999999,"bin_end":100.17,"count":6},{"bin_start":100.17,"bin_end":100.33,"count":0},{"bin_start":100.33,"bin_end":100.49,"count":2},{"bin_start":100.49,"bin_end":100.65,"count":0},{"bin_start":100.65,"bin_end":100.81,"count":0},{"bin_start":100.81,"bin_end":100.97,"count":0},{"bin_start":100.97,"bin_end":101.13,"count":0},{"bin_start":101.13,"bin_end":101.29,"count":0},{"bin_start":101.29,"bin_end":101.45,"count":4}]}},{"name":"1 Bulan","dtype":"float64","stats":{"unique_count":84,"nan_count":0,"min":"-4.29","max":"2.08","histogram":[{"bin_start":-4.29,"bin_end":-3.653,"count":2},{"bin_start":-3.653,"bin_end":-3.016,"count":0},{"bin_start":-3.016,"bin_end":-2.379,"count":1},{"bin_start":-2.379,"bin_end":-1.742,"count":1},{"bin_start":-1.742,"bin_end":-1.105,"count":1},{"bin_start":-1.105,"bin_end":-0.46799999999999997,"count":3},{"bin_start":-0.46799999999999997,"bin_end":0.1689999999999996,"count":13},{"bin_start":0.1689999999999996,"bin_end":0.806,"count":61},{"bin_start":0.806,"bin_end":1.4430000000000005,"count":20},{"bin_start":1.4430000000000005,"bin_end":2.08,"count":10}]}},{"name":"3 Bulan","dtype":"float64","stats":{"unique_count":98,"nan_count":0,"min":"-11.34","max":"10.53","histogram":[{"bin_start":-11.34,"bin_end":-9.153,"count":1},{"bin_start":-9.153,"bin_end":-6.966,"count":1},{"bin_start":-6.966,"bin_end":-4.779,"count":1},{"bin_start":-4.779,"bin_end":-2.5920000000000005,"count":9},{"bin_start":-2.5920000000000005,"bin_end":-0.40500000000000114,"count":13},{"bin_start":-0.40500000000000114,"bin_end":1.782,"count":58},{"bin_start":1.782,"bin_end":3.9689999999999994,"count":21},{"bin_start":3.9689999999999994,"bin_end":6.155999999999999,"count":6},{"bin_start":6.155999999999999,"bin_end":8.343,"count":0},{"bin_start":8.343,"bin_end":10.53,"count":2}]}},{"name":"6 Bulan","dtype":"float64","stats":{"unique_count":93,"nan_count":0,"min":"-12.89","max":"7.86","histogram":[{"bin_start":-12.89,"bin_end":-10.815000000000001,"count":3},{"bin_start":-10.815000000000001,"bin_end":-8.74,"count":1},{"bin_start":-8.74,"bin_end":-6.665,"count":0},{"bin_start":-6.665,"bin_end":-4.59,"count":3},{"bin_start":-4.59,"bin_end":-2.5150000000000006,"count":4},{"bin_start":-2.5150000000000006,"bin_end":-0.4399999999999995,"count":12},{"bin_start":-0.4399999999999995,"bin_end":1.6350000000000016,"count":22},{"bin_start":1.6350000000000016,"bin_end":3.710000000000001,"count":45},{"bin_start":3.710000000000001,"bin_end":5.785,"count":14},{"bin_start":5.785,"bin_end":7.86,"count":8}]}},{"name":"1 Tahun","dtype":"float64","stats":{"unique_count":102,"nan_count":0,"min":"-17.21","max":"9.47","histogram":[{"bin_start":-17.21,"bin_end":-14.542000000000002,"count":2},{"bin_start":-14.542000000000002,"bin_end":-11.874,"count":2},{"bin_start":-11.874,"bin_end":-9.206,"count":3},{"bin_start":-9.206,"bin_end":-6.538,"count":3},{"bin_start":-6.538,"bin_end":-3.870000000000001,"count":2},{"bin_start":-3.870000000000001,"bin_end":-1.2019999999999982,"count":3},{"bin_start":-1.2019999999999982,"bin_end":1.466000000000001,"count":13},{"bin_start":1.466000000000001,"bin_end":4.134,"count":46},{"bin_start":4.134,"bin_end":6.802,"count":25},{"bin_start":6.802,"bin_end":9.47,"count":13}]}},{"name":"3 Tahun","dtype":"float64","stats":{"unique_count":91,"nan_count":0,"min":"-7.91","max":"56.38","histogram":[{"bin_start":-7.91,"bin_end":-1.4809999999999999,"count":4},{"bin_start":-1.4809999999999999,"bin_end":4.948,"count":35},{"bin_start":4.948,"bin_end":11.376999999999999,"count":8},{"bin_start":11.376999999999999,"bin_end":17.806,"count":28},{"bin_start":17.806,"bin_end":24.235000000000003,"count":24},{"bin_start":24.235000000000003,"bin_end":30.663999999999998,"count":9},{"bin_start":30.663999999999998,"bin_end":37.093,"count":0},{"bin_start":37.093,"bin_end":43.522000000000006,"count":0},{"bin_start":43.522000000000006,"bin_end":49.95100000000001,"count":0},{"bin_start":49.95100000000001,"bin_end":56.38,"count":4}]}},{"name":"5 Tahun","dtype":"float64","stats":{"unique_count":91,"nan_count":0,"min":"-17.03","max":"44.49","histogram":[{"bin_start":-17.03,"bin_end":-10.878,"count":2},{"bin_start":-10.878,"bin_end":-4.726000000000001,"count":2},{"bin_start":-4.726000000000001,"bin_end":1.4259999999999984,"count":24},{"bin_start":1.4259999999999984,"bin_end":7.577999999999999,"count":18},{"bin_start":7.577999999999999,"bin_end":13.73,"count":8},{"bin_start":13.73,"bin_end":19.881999999999998,"count":12},{"bin_start":19.881999999999998,"bin_end":26.034,"count":2},{"bin_start":26.034,"bin_end":32.186,"count":16},{"bin_start":32.186,"bin_end":38.338,"count":16},{"bin_start":38.338,"bin_end":44.49,"count":12}]}},{"name":"AUM (M)","dtype":"float64","stats":{"unique_count":80,"nan_count":0,"min":"0.0","max":"9460.0","histogram":[{"bin_start":0,"bin_end":946,"count":92},{"bin_start":946,"bin_end":1892,"count":12},{"bin_start":1892,"bin_end":2838,"count":4},{"bin_start":2838,"bin_end":3784,"count":0},{"bin_start":3784,"bin_end":4730,"count":0},{"bin_start":4730,"bin_end":5676,"count":0},{"bin_start":5676,"bin_end":6622,"count":0},{"bin_start":6622,"bin_end":7568,"count":0},{"bin_start":7568,"bin_end":8514,"count":0},{"bin_start":8514,"bin_end":9460,"count":4}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"Tanggal":"Januari 2023","Merek":"Allianz","DPLK":"DPLK_Equity_Fund","Tipe Risiko":"Agresif","Saham":88.98,"Pasar Uang / Kas":11.02,"Obligasi / SBN / Sukuk":0,"Total Invest":100,"1 Bulan":1.73,"3 Bulan":-2.37,"6 Bulan":-2.6,"1 Tahun":0.68,"3 Tahun":16.83,"5 Tahun":8.18,"AUM (M)":213.42,"_deepnote_index_column":0},{"Tanggal":"Februari 2023","Merek":"Allianz","DPLK":"DPLK_Equity_Fund","Tipe Risiko":"Agresif","Saham":90.68,"Pasar Uang / Kas":9.32,"Obligasi / SBN / Sukuk":0,"Total Invest":100,"1 Bulan":-0.22,"3 Bulan":-3.86,"6 Bulan":-4.75,"1 Tahun":-1.7,"3 Tahun":26.03,"5 Tahun":7.81,"AUM (M)":214.6,"_deepnote_index_column":1},{"Tanggal":"Maret 2023","Merek":"Allianz","DPLK":"DPLK_Equity_Fund","Tipe Risiko":"Agresif","Saham":87.87,"Pasar Uang / Kas":12.13,"Obligasi / SBN / Sukuk":0,"Total Invest":100,"1 Bulan":-0.2,"3 Bulan":1.29,"6 Bulan":-2.69,"1 Tahun":-7.8,"3 Tahun":56.38,"5 Tahun":13.69,"AUM (M)":215.06,"_deepnote_index_column":2},{"Tanggal":"April 2023","Merek":"Allianz","DPLK":"DPLK_Equity_Fund","Tipe Risiko":"Agresif","Saham":92.74,"Pasar Uang / Kas":7.26,"Obligasi / SBN / Sukuk":0,"Total Invest":100,"1 Bulan":2.07,"3 Bulan":1.63,"6 Bulan":-0.78,"1 Tahun":-9.54,"3 Tahun":52.17,"5 Tahun":20.39,"AUM (M)":219.19,"_deepnote_index_column":3},{"Tanggal":"Januari 2023","Merek":"Allianz","DPLK":"DPLK_Fixed_Income","Tipe Risiko":"Moderat","Saham":0,"Pasar Uang / Kas":5.49,"Obligasi / SBN / Sukuk":94.51,"Total Invest":100,"1 Bulan":1.36,"3 Bulan":5.48,"6 Bulan":4.93,"1 Tahun":5.16,"3 Tahun":22.17,"5 Tahun":39.93,"AUM (M)":246.37,"_deepnote_index_column":4},{"Tanggal":"Februari 2023","Merek":"Allianz","DPLK":"DPLK_Fixed_Income","Tipe Risiko":"Moderat","Saham":0,"Pasar Uang / Kas":4.13,"Obligasi / SBN / Sukuk":95.87,"Total Invest":100,"1 Bulan":-0.08,"3 Bulan":2.16,"6 Bulan":3.94,"1 Tahun":4.57,"3 Tahun":22.58,"5 Tahun":41.39,"AUM (M)":246.84,"_deepnote_index_column":5},{"Tanggal":"Maret 2023","Merek":"Allianz","DPLK":"DPLK_Fixed_Income","Tipe Risiko":"Moderat","Saham":0,"Pasar Uang / Kas":3.14,"Obligasi / SBN / Sukuk":96.86,"Total Invest":100,"1 Bulan":1.01,"3 Bulan":2.31,"6 Bulan":6.11,"1 Tahun":6.3,"3 Tahun":29.63,"5 Tahun":41.99,"AUM (M)":252.23,"_deepnote_index_column":6},{"Tanggal":"April 2023","Merek":"Allianz","DPLK":"DPLK_Fixed_Income","Tipe Risiko":"Moderat","Saham":0,"Pasar Uang / Kas":7.11,"Obligasi / SBN / Sukuk":92.89,"Total Invest":100,"1 Bulan":1.04,"3 Bulan":1.99,"6 Bulan":7.57,"1 Tahun":8.27,"3 Tahun":29.2,"5 Tahun":44.49,"AUM (M)":254.71,"_deepnote_index_column":7},{"Tanggal":"Januari 2023","Merek":"Allianz","DPLK":"DPLK_Money_Market_Fund","Tipe Risiko":"Konservatif","Saham":0,"Pasar Uang / Kas":99.99,"Obligasi / SBN / Sukuk":0.01,"Total Invest":100,"1 Bulan":0.44,"3 Bulan":1.22,"6 Bulan":2.05,"1 Tahun":3.48,"3 Tahun":13.63,"5 Tahun":30.7,"AUM (M)":1323.96,"_deepnote_index_column":8},{"Tanggal":"Februari 2023","Merek":"Allianz","DPLK":"DPLK_Money_Market_Fund","Tipe Risiko":"Konservatif","Saham":0,"Pasar Uang / Kas":98.37,"Obligasi / SBN / Sukuk":1.63,"Total Invest":100,"1 Bulan":0.42,"3 Bulan":1.28,"6 Bulan":2.21,"1 Tahun":3.71,"3 Tahun":13.57,"5 Tahun":30.58,"AUM (M)":1260.58,"_deepnote_index_column":9}]},"text/plain":"           Tanggal      Merek                    DPLK  Tipe Risiko  Saham  \\\n0     Januari 2023    Allianz        DPLK_Equity_Fund      Agresif  88.98   \n1    Februari 2023    Allianz        DPLK_Equity_Fund      Agresif  90.68   \n2       Maret 2023    Allianz        DPLK_Equity_Fund      Agresif  87.87   \n3       April 2023    Allianz        DPLK_Equity_Fund      Agresif  92.74   \n4     Januari 2023    Allianz       DPLK_Fixed_Income      Moderat   0.00   \n..             ...        ...                     ...          ...    ...   \n107     April 2023  SimasJaya    Siji_Pensiun_Bahagia  Konservatif   1.21   \n108   Januari 2023  SimasJaya  Siji_Pensiun_Sejahtera  Konservatif   0.00   \n109  Februari 2023  SimasJaya  Siji_Pensiun_Sejahtera  Konservatif   0.00   \n110     Maret 2023  SimasJaya  Siji_Pensiun_Sejahtera  Konservatif   0.00   \n111     April 2023  SimasJaya  Siji_Pensiun_Sejahtera  Konservatif   0.00   \n\n     Pasar Uang / Kas  Obligasi / SBN / Sukuk  Total Invest  1 Bulan  3 Bulan  \\\n0               11.02                    0.00        100.00     1.73    -2.37   \n1                9.32                    0.00        100.00    -0.22    -3.86   \n2               12.13                    0.00        100.00    -0.20     1.29   \n3                7.26                    0.00        100.00     2.07     1.63   \n4                5.49                   94.51        100.00     1.36     5.48   \n..                ...                     ...           ...      ...      ...   \n107              6.49                   92.31        100.01     0.98    10.52   \n108              7.96                   92.04        100.00     1.04     4.20   \n109              3.94                   96.06        100.00     0.27     1.84   \n110              5.19                   94.81        100.00     0.70     2.02   \n111              8.07                   91.93        100.00     0.80    10.53   \n\n     6 Bulan  1 Tahun  3 Tahun  5 Tahun  AUM (M)  \n0      -2.60     0.68    16.83     8.18   213.42  \n1      -4.75    -1.70    26.03     7.81   214.60  \n2      -2.69    -7.80    56.38    13.69   215.06  \n3      -0.78    -9.54    52.17    20.39   219.19  \n4       4.93     5.16    22.17    39.93   246.37  \n..       ...      ...      ...      ...      ...  \n107     6.09     9.17     0.00     0.00   111.76  \n108     4.72     8.60     0.00     0.00   125.00  \n109     3.43     7.58     0.00     0.00   202.66  \n110     4.87     8.32     0.00     0.00   200.85  \n111     6.05     9.47     0.00     0.00   230.27  \n\n[112 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tanggal</th>\n      <th>Merek</th>\n      <th>DPLK</th>\n      <th>Tipe Risiko</th>\n      <th>Saham</th>\n      <th>Pasar Uang / Kas</th>\n      <th>Obligasi / SBN / Sukuk</th>\n      <th>Total Invest</th>\n      <th>1 Bulan</th>\n      <th>3 Bulan</th>\n      <th>6 Bulan</th>\n      <th>1 Tahun</th>\n      <th>3 Tahun</th>\n      <th>5 Tahun</th>\n      <th>AUM (M)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Januari 2023</td>\n      <td>Allianz</td>\n      <td>DPLK_Equity_Fund</td>\n      <td>Agresif</td>\n      <td>88.98</td>\n      <td>11.02</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>1.73</td>\n      <td>-2.37</td>\n      <td>-2.60</td>\n      <td>0.68</td>\n      <td>16.83</td>\n      <td>8.18</td>\n      <td>213.42</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Februari 2023</td>\n      <td>Allianz</td>\n      <td>DPLK_Equity_Fund</td>\n      <td>Agresif</td>\n      <td>90.68</td>\n      <td>9.32</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>-0.22</td>\n      <td>-3.86</td>\n      <td>-4.75</td>\n      <td>-1.70</td>\n      <td>26.03</td>\n      <td>7.81</td>\n      <td>214.60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Maret 2023</td>\n      <td>Allianz</td>\n      <td>DPLK_Equity_Fund</td>\n      <td>Agresif</td>\n      <td>87.87</td>\n      <td>12.13</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>-0.20</td>\n      <td>1.29</td>\n      <td>-2.69</td>\n      <td>-7.80</td>\n      <td>56.38</td>\n      <td>13.69</td>\n      <td>215.06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>April 2023</td>\n      <td>Allianz</td>\n      <td>DPLK_Equity_Fund</td>\n      <td>Agresif</td>\n      <td>92.74</td>\n      <td>7.26</td>\n      <td>0.00</td>\n      <td>100.00</td>\n      <td>2.07</td>\n      <td>1.63</td>\n      <td>-0.78</td>\n      <td>-9.54</td>\n      <td>52.17</td>\n      <td>20.39</td>\n      <td>219.19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Januari 2023</td>\n      <td>Allianz</td>\n      <td>DPLK_Fixed_Income</td>\n      <td>Moderat</td>\n      <td>0.00</td>\n      <td>5.49</td>\n      <td>94.51</td>\n      <td>100.00</td>\n      <td>1.36</td>\n      <td>5.48</td>\n      <td>4.93</td>\n      <td>5.16</td>\n      <td>22.17</td>\n      <td>39.93</td>\n      <td>246.37</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>April 2023</td>\n      <td>SimasJaya</td>\n      <td>Siji_Pensiun_Bahagia</td>\n      <td>Konservatif</td>\n      <td>1.21</td>\n      <td>6.49</td>\n      <td>92.31</td>\n      <td>100.01</td>\n      <td>0.98</td>\n      <td>10.52</td>\n      <td>6.09</td>\n      <td>9.17</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>111.76</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>Januari 2023</td>\n      <td>SimasJaya</td>\n      <td>Siji_Pensiun_Sejahtera</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>7.96</td>\n      <td>92.04</td>\n      <td>100.00</td>\n      <td>1.04</td>\n      <td>4.20</td>\n      <td>4.72</td>\n      <td>8.60</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>125.00</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>Februari 2023</td>\n      <td>SimasJaya</td>\n      <td>Siji_Pensiun_Sejahtera</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>3.94</td>\n      <td>96.06</td>\n      <td>100.00</td>\n      <td>0.27</td>\n      <td>1.84</td>\n      <td>3.43</td>\n      <td>7.58</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>202.66</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>Maret 2023</td>\n      <td>SimasJaya</td>\n      <td>Siji_Pensiun_Sejahtera</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>5.19</td>\n      <td>94.81</td>\n      <td>100.00</td>\n      <td>0.70</td>\n      <td>2.02</td>\n      <td>4.87</td>\n      <td>8.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>200.85</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>April 2023</td>\n      <td>SimasJaya</td>\n      <td>Siji_Pensiun_Sejahtera</td>\n      <td>Konservatif</td>\n      <td>0.00</td>\n      <td>8.07</td>\n      <td>91.93</td>\n      <td>100.00</td>\n      <td>0.80</td>\n      <td>10.53</td>\n      <td>6.05</td>\n      <td>9.47</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>230.27</td>\n    </tr>\n  </tbody>\n</table>\n<p>112 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":"957547ae","execution_start":1686315127966,"execution_millis":5,"deepnote_to_be_reexecuted":false,"cell_id":"66bf46fbe9364c0aa747aacdc189b237","deepnote_cell_type":"code"},"source":"data.info()","execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 112 entries, 0 to 111\nData columns (total 15 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   Tanggal                 112 non-null    object \n 1   Merek                   112 non-null    object \n 2   DPLK                    112 non-null    object \n 3   Tipe Risiko             112 non-null    object \n 4   Saham                   104 non-null    float64\n 5   Pasar Uang / Kas        112 non-null    float64\n 6   Obligasi / SBN / Sukuk  112 non-null    float64\n 7   Total Invest            112 non-null    float64\n 8   1 Bulan                 112 non-null    float64\n 9   3 Bulan                 112 non-null    float64\n 10  6 Bulan                 100 non-null    float64\n 11  1 Tahun                 112 non-null    float64\n 12  3 Tahun                 92 non-null     float64\n 13  5 Tahun                 92 non-null     float64\n 14  AUM (M)                 84 non-null     float64\ndtypes: float64(11), object(4)\nmemory usage: 13.2+ KB\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"75c31b39","execution_start":1686315127999,"execution_millis":2,"deepnote_to_be_reexecuted":false,"cell_id":"4a7dc8e6afdb4bb5a3c339368c8fd541","deepnote_cell_type":"code"},"source":"# Split the data into features and labels\nfeatures = data.drop(['Tanggal', 'Merek', 'Tipe Risiko', 'DPLK', 'Total Invest'], axis=1)\nfeatures = features.fillna(0)\nlabels = data['Tipe Risiko']\n\nreshaped_features = pd.DataFrame(features.values.reshape((features.shape[0]//4, features.shape[1]*4)))\n\n\n# Encode the labels into numeric values\nlabel_encoder = LabelEncoder()\nlabels = label_encoder.fit_transform(labels)\nreshaped_labels = labels[::4]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"6115124c","execution_start":1686315127999,"execution_millis":2,"deepnote_to_be_reexecuted":false,"cell_id":"d70a92126540499db10275c179d9d9af","deepnote_cell_type":"code"},"source":"X_train.info","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"<bound method DataFrame.info of      Saham  Pasar Uang / Kas  Obligasi / SBN / Sukuk  1 Bulan  3 Bulan  \\\n66    0.00              8.29                   91.71     0.86     2.60   \n90    0.00            100.00                    0.00    -1.24    -3.53   \n62   99.25              0.75                    0.00    -2.94    -1.33   \n22    0.00             88.03                   11.97     0.48     1.37   \n85    0.00            100.00                    0.00     0.41     1.24   \n..     ...               ...                     ...      ...      ...   \n106   1.08              6.12                   92.80     0.84     2.16   \n14   89.14             10.86                    0.00    -0.21     1.22   \n92    0.00             85.17                   14.83     0.53     1.50   \n51    0.00             62.91                   37.09     0.54     1.57   \n102  20.01             79.99                    0.00     0.37     0.73   \n\n     6 Bulan  1 Tahun  3 Tahun  5 Tahun  AUM (M)  \n66      0.00     7.32     0.00     0.00    88.51  \n90     -1.12     4.85    -1.24     3.87    75.84  \n62      0.00   -11.50     0.00     0.00    64.46  \n22      2.44     3.88    13.28    30.07   998.26  \n85      2.05     3.58     4.27     5.35   637.21  \n..       ...      ...      ...      ...      ...  \n106     4.69     7.95     0.00     0.00   110.89  \n14     -2.79    -8.06    54.98     8.44    35.04  \n92      2.58     4.42    17.41    32.70   893.86  \n51      3.32     4.62    19.77    35.35     0.00  \n102    -1.67    -0.35    21.62    -7.51    85.19  \n\n[89 rows x 10 columns]>"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":"2709fcf","execution_start":1686315128001,"execution_millis":21868,"deepnote_to_be_reexecuted":false,"cell_id":"4ba8ee3df6dd462488469e3108f4b3e5","deepnote_cell_type":"code"},"source":"# Build the neural network model\nmodel = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=(len(X_train.columns),), kernel_regularizer=regularizers.l2(0.01)),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n    layers.Dropout(0.3),\n    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n    layers.Dropout(0.3),\n    layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n    layers.Dropout(0.3),\n    layers.Dense(3, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=1000, batch_size=32)\n\n# Evaluate the model\n_, accuracy = model.evaluate(X_test, y_test)\nprint('Accuracy:', accuracy)\n\n# Make predictions\npredictions = model.predict(X_test)\n","execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 503/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3775 - accuracy: 0.7640\nEpoch 504/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3992 - accuracy: 0.7640\nEpoch 505/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4084 - accuracy: 0.7640\nEpoch 506/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3946 - accuracy: 0.7753\nEpoch 507/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4002 - accuracy: 0.7753\nEpoch 508/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4642 - accuracy: 0.7640\nEpoch 509/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4399 - accuracy: 0.8202\nEpoch 510/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4053 - accuracy: 0.7753\nEpoch 511/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3205 - accuracy: 0.8202\nEpoch 512/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4970 - accuracy: 0.7528\nEpoch 513/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.2978 - accuracy: 0.8427\nEpoch 514/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3095 - accuracy: 0.8202\nEpoch 515/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3237 - accuracy: 0.7865\nEpoch 516/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3354 - accuracy: 0.8202\nEpoch 517/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3437 - accuracy: 0.8539\nEpoch 518/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3054 - accuracy: 0.7978\nEpoch 519/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.3048 - accuracy: 0.7753\nEpoch 520/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4254 - accuracy: 0.7640\nEpoch 521/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3171 - accuracy: 0.8315\nEpoch 522/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2873 - accuracy: 0.8315\nEpoch 523/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3232 - accuracy: 0.8202\nEpoch 524/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3303 - accuracy: 0.8202\nEpoch 525/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.5174 - accuracy: 0.7753\nEpoch 526/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3109 - accuracy: 0.8202\nEpoch 527/1000\n3/3 [==============================] - 0s 5ms/step - loss: 1.3478 - accuracy: 0.8090\nEpoch 528/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3153 - accuracy: 0.8202\nEpoch 529/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.5247 - accuracy: 0.7191\nEpoch 530/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2836 - accuracy: 0.8202\nEpoch 531/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2780 - accuracy: 0.8652\nEpoch 532/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3462 - accuracy: 0.7865\nEpoch 533/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3822 - accuracy: 0.7753\nEpoch 534/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3048 - accuracy: 0.8090\nEpoch 535/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3788 - accuracy: 0.8989\nEpoch 536/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3370 - accuracy: 0.7416\nEpoch 537/1000\n3/3 [==============================] - 0s 28ms/step - loss: 1.3280 - accuracy: 0.8427\nEpoch 538/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3145 - accuracy: 0.8652\nEpoch 539/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2850 - accuracy: 0.8090\nEpoch 540/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3576 - accuracy: 0.8090\nEpoch 541/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.7640\nEpoch 542/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3975 - accuracy: 0.7978\nEpoch 543/1000\n3/3 [==============================] - 0s 28ms/step - loss: 1.2593 - accuracy: 0.8315\nEpoch 544/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2868 - accuracy: 0.8652\nEpoch 545/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2893 - accuracy: 0.8090\nEpoch 546/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.3398 - accuracy: 0.8315\nEpoch 547/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2642 - accuracy: 0.8315\nEpoch 548/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.4057 - accuracy: 0.7303\nEpoch 549/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.2727 - accuracy: 0.8202\nEpoch 550/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3294 - accuracy: 0.8090\nEpoch 551/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.5591 - accuracy: 0.8427\nEpoch 552/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2560 - accuracy: 0.8090\nEpoch 553/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2120 - accuracy: 0.8989\nEpoch 554/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2528 - accuracy: 0.8090\nEpoch 555/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.4733 - accuracy: 0.7865\nEpoch 556/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3249 - accuracy: 0.8427\nEpoch 557/1000\n3/3 [==============================] - 0s 5ms/step - loss: 1.3158 - accuracy: 0.7865\nEpoch 558/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.4319 - accuracy: 0.8315\nEpoch 559/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2957 - accuracy: 0.8090\nEpoch 560/1000\n3/3 [==============================] - 0s 25ms/step - loss: 1.3726 - accuracy: 0.7753\nEpoch 561/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3374 - accuracy: 0.8427\nEpoch 562/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2826 - accuracy: 0.8090\nEpoch 563/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3568 - accuracy: 0.7640\nEpoch 564/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3509 - accuracy: 0.8539\nEpoch 565/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2605 - accuracy: 0.8652\nEpoch 566/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.7094 - accuracy: 0.8090\nEpoch 567/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3375 - accuracy: 0.7978\nEpoch 568/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2259 - accuracy: 0.8427\nEpoch 569/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.5288 - accuracy: 0.7865\nEpoch 570/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.5156 - accuracy: 0.8090\nEpoch 571/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2546 - accuracy: 0.8202\nEpoch 572/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3010 - accuracy: 0.8427\nEpoch 573/1000\n3/3 [==============================] - 0s 28ms/step - loss: 1.4662 - accuracy: 0.7416\nEpoch 574/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3478 - accuracy: 0.8202\nEpoch 575/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2329 - accuracy: 0.8652\nEpoch 576/1000\n3/3 [==============================] - 0s 6ms/step - loss: 1.2058 - accuracy: 0.8427\nEpoch 577/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3025 - accuracy: 0.7528\nEpoch 578/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2581 - accuracy: 0.8652\nEpoch 579/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3264 - accuracy: 0.7753\nEpoch 580/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2383 - accuracy: 0.8427\nEpoch 581/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3732 - accuracy: 0.7528\nEpoch 582/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2544 - accuracy: 0.8427\nEpoch 583/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2048 - accuracy: 0.8652\nEpoch 584/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4270 - accuracy: 0.8315\nEpoch 585/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2759 - accuracy: 0.8652\nEpoch 586/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.8315\nEpoch 587/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2268 - accuracy: 0.8539\nEpoch 588/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2219 - accuracy: 0.8764\nEpoch 589/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3482 - accuracy: 0.7978\nEpoch 590/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2468 - accuracy: 0.8427\nEpoch 591/1000\n3/3 [==============================] - 0s 24ms/step - loss: 1.2404 - accuracy: 0.8427\nEpoch 592/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3180 - accuracy: 0.8539\nEpoch 593/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2484 - accuracy: 0.8539\nEpoch 594/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2242 - accuracy: 0.8315\nEpoch 595/1000\n3/3 [==============================] - 0s 5ms/step - loss: 1.1887 - accuracy: 0.8539\nEpoch 596/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2937 - accuracy: 0.8090\nEpoch 597/1000\n3/3 [==============================] - 0s 24ms/step - loss: 1.2607 - accuracy: 0.8427\nEpoch 598/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1784 - accuracy: 0.8764\nEpoch 599/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2626 - accuracy: 0.8652\nEpoch 600/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4375 - accuracy: 0.8315\nEpoch 601/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2433 - accuracy: 0.7978\nEpoch 602/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2093 - accuracy: 0.8427\nEpoch 603/1000\n3/3 [==============================] - 0s 28ms/step - loss: 1.2170 - accuracy: 0.7865\nEpoch 604/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2036 - accuracy: 0.8202\nEpoch 605/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2239 - accuracy: 0.8539\nEpoch 606/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1474 - accuracy: 0.8764\nEpoch 607/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2434 - accuracy: 0.8202\nEpoch 608/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2317 - accuracy: 0.7978\nEpoch 609/1000\n3/3 [==============================] - 0s 19ms/step - loss: 1.2205 - accuracy: 0.8090\nEpoch 610/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2191 - accuracy: 0.8427\nEpoch 611/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2695 - accuracy: 0.8202\nEpoch 612/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2398 - accuracy: 0.9101\nEpoch 613/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1838 - accuracy: 0.8764\nEpoch 614/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.3665 - accuracy: 0.8427\nEpoch 615/1000\n3/3 [==============================] - 0s 27ms/step - loss: 1.1793 - accuracy: 0.8989\nEpoch 616/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2562 - accuracy: 0.8202\nEpoch 617/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1537 - accuracy: 0.8876\nEpoch 618/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2733 - accuracy: 0.8539\nEpoch 619/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1896 - accuracy: 0.8539\nEpoch 620/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1698 - accuracy: 0.9101\nEpoch 621/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1283 - accuracy: 0.8764\nEpoch 622/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2868 - accuracy: 0.8202\nEpoch 623/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1357 - accuracy: 0.8764\nEpoch 624/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1592 - accuracy: 0.9101\nEpoch 625/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1989 - accuracy: 0.8427\nEpoch 626/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1874 - accuracy: 0.8652\nEpoch 627/1000\n3/3 [==============================] - 0s 27ms/step - loss: 1.2930 - accuracy: 0.8090\nEpoch 628/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2314 - accuracy: 0.8427\nEpoch 629/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1639 - accuracy: 0.8315\nEpoch 630/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1580 - accuracy: 0.8764\nEpoch 631/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.4211 - accuracy: 0.8427\nEpoch 632/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1649 - accuracy: 0.8876\nEpoch 633/1000\n3/3 [==============================] - 0s 27ms/step - loss: 1.1840 - accuracy: 0.8652\nEpoch 634/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.5476 - accuracy: 0.8427\nEpoch 635/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1251 - accuracy: 0.9213\nEpoch 636/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1131 - accuracy: 0.8876\nEpoch 637/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2085 - accuracy: 0.8539\nEpoch 638/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.2856 - accuracy: 0.8315\nEpoch 639/1000\n3/3 [==============================] - 0s 24ms/step - loss: 1.2897 - accuracy: 0.7753\nEpoch 640/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3027 - accuracy: 0.7978\nEpoch 641/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1739 - accuracy: 0.8539\nEpoch 642/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2102 - accuracy: 0.8202\nEpoch 643/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.1230 - accuracy: 0.8652\nEpoch 644/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1741 - accuracy: 0.8427\nEpoch 645/1000\n3/3 [==============================] - 0s 24ms/step - loss: 1.1263 - accuracy: 0.8989\nEpoch 646/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2255 - accuracy: 0.8539\nEpoch 647/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1635 - accuracy: 0.8652\nEpoch 648/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1260 - accuracy: 0.8539\nEpoch 649/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1003 - accuracy: 0.9213\nEpoch 650/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1361 - accuracy: 0.8876\nEpoch 651/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0979 - accuracy: 0.8989\nEpoch 652/1000\n3/3 [==============================] - 0s 22ms/step - loss: 1.1725 - accuracy: 0.8876\nEpoch 653/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1842 - accuracy: 0.8764\nEpoch 654/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1138 - accuracy: 0.9101\nEpoch 655/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1018 - accuracy: 0.8764\nEpoch 656/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2583 - accuracy: 0.8315\nEpoch 657/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1705 - accuracy: 0.8989\nEpoch 658/1000\n3/3 [==============================] - 0s 29ms/step - loss: 1.1213 - accuracy: 0.8652\nEpoch 659/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2461 - accuracy: 0.7640\nEpoch 660/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.3315 - accuracy: 0.7865\nEpoch 661/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.8876\nEpoch 662/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1089 - accuracy: 0.8539\nEpoch 663/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1176 - accuracy: 0.8539\nEpoch 664/1000\n3/3 [==============================] - 0s 21ms/step - loss: 1.2198 - accuracy: 0.8090\nEpoch 665/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1368 - accuracy: 0.8876\nEpoch 666/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1354 - accuracy: 0.8539\nEpoch 667/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.1960 - accuracy: 0.8202\nEpoch 668/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2776 - accuracy: 0.8427\nEpoch 669/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2000 - accuracy: 0.8652\nEpoch 670/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.8427\nEpoch 671/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1740 - accuracy: 0.8202\nEpoch 672/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1031 - accuracy: 0.8876\nEpoch 673/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0979 - accuracy: 0.9326\nEpoch 674/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1452 - accuracy: 0.8652\nEpoch 675/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2170 - accuracy: 0.8315\nEpoch 676/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1119 - accuracy: 0.8876\nEpoch 677/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0756 - accuracy: 0.9213\nEpoch 678/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1326 - accuracy: 0.8427\nEpoch 679/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.1077 - accuracy: 0.8539\nEpoch 680/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.1334 - accuracy: 0.8427\nEpoch 681/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2099 - accuracy: 0.8427\nEpoch 682/1000\n3/3 [==============================] - 0s 25ms/step - loss: 1.0762 - accuracy: 0.8764\nEpoch 683/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1095 - accuracy: 0.8539\nEpoch 684/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0856 - accuracy: 0.8652\nEpoch 685/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1251 - accuracy: 0.8539\nEpoch 686/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1221 - accuracy: 0.8652\nEpoch 687/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0684 - accuracy: 0.9101\nEpoch 688/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1200 - accuracy: 0.8764\nEpoch 689/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.2767 - accuracy: 0.8202\nEpoch 690/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0842 - accuracy: 0.8876\nEpoch 691/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0867 - accuracy: 0.8876\nEpoch 692/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1103 - accuracy: 0.8989\nEpoch 693/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2031 - accuracy: 0.8539\nEpoch 694/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0576 - accuracy: 0.8539\nEpoch 695/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.9326\nEpoch 696/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0980 - accuracy: 0.8652\nEpoch 697/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0644 - accuracy: 0.9213\nEpoch 698/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1448 - accuracy: 0.8764\nEpoch 699/1000\n3/3 [==============================] - 0s 5ms/step - loss: 1.0537 - accuracy: 0.8989\nEpoch 700/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0134 - accuracy: 0.9326\nEpoch 701/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0802 - accuracy: 0.9213\nEpoch 702/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1414 - accuracy: 0.8989\nEpoch 703/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1143 - accuracy: 0.8764\nEpoch 704/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0703 - accuracy: 0.8989\nEpoch 705/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0555 - accuracy: 0.9101\nEpoch 706/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1878 - accuracy: 0.8652\nEpoch 707/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0821 - accuracy: 0.9101\nEpoch 708/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1481 - accuracy: 0.8764\nEpoch 709/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.6290 - accuracy: 0.8427\nEpoch 710/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1203 - accuracy: 0.8652\nEpoch 711/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0735 - accuracy: 0.8652\nEpoch 712/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1446 - accuracy: 0.8764\nEpoch 713/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1222 - accuracy: 0.8652\nEpoch 714/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0735 - accuracy: 0.8989\nEpoch 715/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1997 - accuracy: 0.8876\nEpoch 716/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0872 - accuracy: 0.8764\nEpoch 717/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1141 - accuracy: 0.8764\nEpoch 718/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0277 - accuracy: 0.8989\nEpoch 719/1000\n3/3 [==============================] - 0s 27ms/step - loss: 1.1542 - accuracy: 0.8876\nEpoch 720/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1149 - accuracy: 0.8539\nEpoch 721/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0701 - accuracy: 0.9101\nEpoch 722/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0910 - accuracy: 0.8876\nEpoch 723/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0754 - accuracy: 0.9101\nEpoch 724/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1477 - accuracy: 0.8539\nEpoch 725/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1466 - accuracy: 0.8652\nEpoch 726/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.9326\nEpoch 727/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1309 - accuracy: 0.8764\nEpoch 728/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0781 - accuracy: 0.8876\nEpoch 729/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0605 - accuracy: 0.9213\nEpoch 730/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1367 - accuracy: 0.9101\nEpoch 731/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.8652\nEpoch 732/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1511 - accuracy: 0.8652\nEpoch 733/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1203 - accuracy: 0.9101\nEpoch 734/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0810 - accuracy: 0.8764\nEpoch 735/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.9101\nEpoch 736/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0231 - accuracy: 0.9213\nEpoch 737/1000\n3/3 [==============================] - 0s 5ms/step - loss: 1.1645 - accuracy: 0.9101\nEpoch 738/1000\n3/3 [==============================] - 0s 23ms/step - loss: 1.0587 - accuracy: 0.8652\nEpoch 739/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0480 - accuracy: 0.8989\nEpoch 740/1000\n3/3 [==============================] - 0s 6ms/step - loss: 1.0307 - accuracy: 0.8989\nEpoch 741/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.0359 - accuracy: 0.9213\nEpoch 742/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0588 - accuracy: 0.8652\nEpoch 743/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0449 - accuracy: 0.8876\nEpoch 744/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1175 - accuracy: 0.8764\nEpoch 745/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0996 - accuracy: 0.8876\nEpoch 746/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9672 - accuracy: 0.9551\nEpoch 747/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1099 - accuracy: 0.8989\nEpoch 748/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0182 - accuracy: 0.9213\nEpoch 749/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9952 - accuracy: 0.9101\nEpoch 750/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.9920 - accuracy: 0.9213\nEpoch 751/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0794 - accuracy: 0.8652\nEpoch 752/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1374 - accuracy: 0.9101\nEpoch 753/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0241 - accuracy: 0.9101\nEpoch 754/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0380 - accuracy: 0.9213\nEpoch 755/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0634 - accuracy: 0.8539\nEpoch 756/1000\n3/3 [==============================] - 0s 26ms/step - loss: 0.9774 - accuracy: 0.9438\nEpoch 757/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.1693 - accuracy: 0.9101\nEpoch 758/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0234 - accuracy: 0.8652\nEpoch 759/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.2095 - accuracy: 0.8876\nEpoch 760/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.0010 - accuracy: 0.9326\nEpoch 761/1000\n3/3 [==============================] - 0s 7ms/step - loss: 1.0713 - accuracy: 0.9101\nEpoch 762/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.0556 - accuracy: 0.8876\nEpoch 763/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0029 - accuracy: 0.9213\nEpoch 764/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0250 - accuracy: 0.9326\nEpoch 765/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0198 - accuracy: 0.9438\nEpoch 766/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0059 - accuracy: 0.9101\nEpoch 767/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0949 - accuracy: 0.8764\nEpoch 768/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.9826 - accuracy: 0.9326\nEpoch 769/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9663 - accuracy: 0.9438\nEpoch 770/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0326 - accuracy: 0.9326\nEpoch 771/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0388 - accuracy: 0.8652\nEpoch 772/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9580 - accuracy: 0.9213\nEpoch 773/1000\n3/3 [==============================] - 0s 22ms/step - loss: 0.9646 - accuracy: 0.9326\nEpoch 774/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9873 - accuracy: 0.8989\nEpoch 775/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1991 - accuracy: 0.9213\nEpoch 776/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1003 - accuracy: 0.9101\nEpoch 777/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0460 - accuracy: 0.9101\nEpoch 778/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9511 - accuracy: 0.9213\nEpoch 779/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0511 - accuracy: 0.9326\nEpoch 780/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9986 - accuracy: 0.9101\nEpoch 781/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1281 - accuracy: 0.8764\nEpoch 782/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9450 - accuracy: 0.9326\nEpoch 783/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9720 - accuracy: 0.9438\nEpoch 784/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0162 - accuracy: 0.8764\nEpoch 785/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0344 - accuracy: 0.9101\nEpoch 786/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9938 - accuracy: 0.8989\nEpoch 787/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9391 - accuracy: 0.9213\nEpoch 788/1000\n3/3 [==============================] - 0s 4ms/step - loss: 1.0184 - accuracy: 0.8876\nEpoch 789/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0466 - accuracy: 0.8764\nEpoch 790/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0022 - accuracy: 0.9213\nEpoch 791/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.9442 - accuracy: 0.9326\nEpoch 792/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9393 - accuracy: 0.9438\nEpoch 793/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.9438\nEpoch 794/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.8989\nEpoch 795/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9786 - accuracy: 0.8876\nEpoch 796/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9208 - accuracy: 0.9663\nEpoch 797/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.9326\nEpoch 798/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9884 - accuracy: 0.9438\nEpoch 799/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1093 - accuracy: 0.8652\nEpoch 800/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9703 - accuracy: 0.9326\nEpoch 801/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9737 - accuracy: 0.9326\nEpoch 802/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9679 - accuracy: 0.9438\nEpoch 803/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.9101\nEpoch 804/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9722 - accuracy: 0.9213\nEpoch 805/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9852 - accuracy: 0.8989\nEpoch 806/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0209 - accuracy: 0.9213\nEpoch 807/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9655 - accuracy: 0.9101\nEpoch 808/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0607 - accuracy: 0.8876\nEpoch 809/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8940 - accuracy: 0.9438\nEpoch 810/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9495 - accuracy: 0.9326\nEpoch 811/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9405 - accuracy: 0.9326\nEpoch 812/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0250 - accuracy: 0.9213\nEpoch 813/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9447 - accuracy: 0.9551\nEpoch 814/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9474 - accuracy: 0.9101\nEpoch 815/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9258 - accuracy: 0.9326\nEpoch 816/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9410 - accuracy: 0.9213\nEpoch 817/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9529 - accuracy: 0.9326\nEpoch 818/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9444 - accuracy: 0.9213\nEpoch 819/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9320 - accuracy: 0.9326\nEpoch 820/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.9213\nEpoch 821/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9446 - accuracy: 0.9213\nEpoch 822/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9192 - accuracy: 0.9326\nEpoch 823/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9067 - accuracy: 0.9551\nEpoch 824/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9190 - accuracy: 0.9438\nEpoch 825/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9807 - accuracy: 0.8989\nEpoch 826/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9351 - accuracy: 0.9213\nEpoch 827/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8969 - accuracy: 0.9551\nEpoch 828/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.8925 - accuracy: 0.9438\nEpoch 829/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.8876\nEpoch 830/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9594 - accuracy: 0.9101\nEpoch 831/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9077 - accuracy: 0.9101\nEpoch 832/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9546 - accuracy: 0.9213\nEpoch 833/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9049 - accuracy: 0.9326\nEpoch 834/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.9558 - accuracy: 0.9213\nEpoch 835/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9893 - accuracy: 0.8989\nEpoch 836/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9277 - accuracy: 0.9213\nEpoch 837/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9751 - accuracy: 0.9213\nEpoch 838/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9466 - accuracy: 0.9326\nEpoch 839/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.9438\nEpoch 840/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8898 - accuracy: 0.9551\nEpoch 841/1000\n3/3 [==============================] - 0s 23ms/step - loss: 0.9645 - accuracy: 0.9101\nEpoch 842/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.9101\nEpoch 843/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.9101\nEpoch 844/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9528 - accuracy: 0.9326\nEpoch 845/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9274 - accuracy: 0.9438\nEpoch 846/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9902 - accuracy: 0.9213\nEpoch 847/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9302 - accuracy: 0.9213\nEpoch 848/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9963 - accuracy: 0.8989\nEpoch 849/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8952 - accuracy: 0.9438\nEpoch 850/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.9113 - accuracy: 0.9438\nEpoch 851/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.9457 - accuracy: 0.8764\nEpoch 852/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0207 - accuracy: 0.8539\nEpoch 853/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8831 - accuracy: 0.9326\nEpoch 854/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9058 - accuracy: 0.9438\nEpoch 855/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9728 - accuracy: 0.8652\nEpoch 856/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9711 - accuracy: 0.9213\nEpoch 857/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0395 - accuracy: 0.9101\nEpoch 858/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9514 - accuracy: 0.8876\nEpoch 859/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8833 - accuracy: 0.9213\nEpoch 860/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9252 - accuracy: 0.9326\nEpoch 861/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9015 - accuracy: 0.9438\nEpoch 862/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8767 - accuracy: 0.9775\nEpoch 863/1000\n3/3 [==============================] - 0s 3ms/step - loss: 1.0223 - accuracy: 0.8989\nEpoch 864/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.9326\nEpoch 865/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9436 - accuracy: 0.9438\nEpoch 866/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.8645 - accuracy: 0.9775\nEpoch 867/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9098 - accuracy: 0.9326\nEpoch 868/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9648 - accuracy: 0.8989\nEpoch 869/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9197 - accuracy: 0.9326\nEpoch 870/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.9551\nEpoch 871/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8812 - accuracy: 0.9663\nEpoch 872/1000\n3/3 [==============================] - 0s 28ms/step - loss: 1.0488 - accuracy: 0.9326\nEpoch 873/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9128 - accuracy: 0.9213\nEpoch 874/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9026 - accuracy: 0.9101\nEpoch 875/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.9663\nEpoch 876/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8762 - accuracy: 0.9438\nEpoch 877/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9315 - accuracy: 0.9101\nEpoch 878/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.9098 - accuracy: 0.8989\nEpoch 879/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.8989\nEpoch 880/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8866 - accuracy: 0.9326\nEpoch 881/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9388 - accuracy: 0.9101\nEpoch 882/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.8527 - accuracy: 0.9551\nEpoch 883/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9546 - accuracy: 0.9326\nEpoch 884/1000\n3/3 [==============================] - 0s 23ms/step - loss: 0.8721 - accuracy: 0.9775\nEpoch 885/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8404 - accuracy: 0.9438\nEpoch 886/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8633 - accuracy: 0.9551\nEpoch 887/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8819 - accuracy: 0.9438\nEpoch 888/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8929 - accuracy: 0.9438\nEpoch 889/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9265 - accuracy: 0.9101\nEpoch 890/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8563 - accuracy: 0.9551\nEpoch 891/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8258 - accuracy: 0.9663\nEpoch 892/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8521 - accuracy: 0.9326\nEpoch 893/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8372 - accuracy: 0.9775\nEpoch 894/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8530 - accuracy: 0.9438\nEpoch 895/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0120 - accuracy: 0.8764\nEpoch 896/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0564 - accuracy: 0.8539\nEpoch 897/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8703 - accuracy: 0.9326\nEpoch 898/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8939 - accuracy: 0.9438\nEpoch 899/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9596 - accuracy: 0.9213\nEpoch 900/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0015 - accuracy: 0.8989\nEpoch 901/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8721 - accuracy: 0.9438\nEpoch 902/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8728 - accuracy: 0.9326\nEpoch 903/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8976 - accuracy: 0.9438\nEpoch 904/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9063 - accuracy: 0.9101\nEpoch 905/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.8989\nEpoch 906/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8869 - accuracy: 0.9101\nEpoch 907/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.0037 - accuracy: 0.9326\nEpoch 908/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8811 - accuracy: 0.9101\nEpoch 909/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8553 - accuracy: 0.9326\nEpoch 910/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.8649 - accuracy: 0.9438\nEpoch 911/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8670 - accuracy: 0.9213\nEpoch 912/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9352 - accuracy: 0.9101\nEpoch 913/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9193 - accuracy: 0.9551\nEpoch 914/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8912 - accuracy: 0.9213\nEpoch 915/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9192 - accuracy: 0.9438\nEpoch 916/1000\n3/3 [==============================] - 0s 24ms/step - loss: 0.8500 - accuracy: 0.9326\nEpoch 917/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8265 - accuracy: 0.9438\nEpoch 918/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8586 - accuracy: 0.9326\nEpoch 919/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9380 - accuracy: 0.9101\nEpoch 920/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8290 - accuracy: 0.9551\nEpoch 921/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.9101\nEpoch 922/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9251 - accuracy: 0.9213\nEpoch 923/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8874 - accuracy: 0.8989\nEpoch 924/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8423 - accuracy: 0.9551\nEpoch 925/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.8929 - accuracy: 0.9101\nEpoch 926/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8744 - accuracy: 0.9101\nEpoch 927/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8918 - accuracy: 0.9326\nEpoch 928/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8486 - accuracy: 0.8989\nEpoch 929/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8399 - accuracy: 0.9551\nEpoch 930/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8230 - accuracy: 0.9663\nEpoch 931/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8454 - accuracy: 0.9551\nEpoch 932/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8335 - accuracy: 0.9663\nEpoch 933/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8573 - accuracy: 0.9551\nEpoch 934/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8457 - accuracy: 0.9551\nEpoch 935/1000\n3/3 [==============================] - 0s 29ms/step - loss: 0.8657 - accuracy: 0.9213\nEpoch 936/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8143 - accuracy: 0.9663\nEpoch 937/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8429 - accuracy: 0.9438\nEpoch 938/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.9663\nEpoch 939/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8404 - accuracy: 0.9326\nEpoch 940/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8629 - accuracy: 0.9438\nEpoch 941/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8912 - accuracy: 0.8989\nEpoch 942/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8754 - accuracy: 0.9101\nEpoch 943/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8388 - accuracy: 0.9438\nEpoch 944/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9160 - accuracy: 0.9101\nEpoch 945/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8375 - accuracy: 0.9326\nEpoch 946/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9502 - accuracy: 0.8876\nEpoch 947/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8178 - accuracy: 0.9663\nEpoch 948/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8969 - accuracy: 0.9213\nEpoch 949/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8987 - accuracy: 0.9101\nEpoch 950/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.9326\nEpoch 951/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8416 - accuracy: 0.9213\nEpoch 952/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8339 - accuracy: 0.9438\nEpoch 953/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9084 - accuracy: 0.8989\nEpoch 954/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.8649 - accuracy: 0.9438\nEpoch 955/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8263 - accuracy: 0.9663\nEpoch 956/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8002 - accuracy: 0.9551\nEpoch 957/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8477 - accuracy: 0.9326\nEpoch 958/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8219 - accuracy: 0.9775\nEpoch 959/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8995 - accuracy: 0.9213\nEpoch 960/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8870 - accuracy: 0.8989\nEpoch 961/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.9326\nEpoch 962/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8357 - accuracy: 0.9326\nEpoch 963/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7947 - accuracy: 0.9551\nEpoch 964/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8511 - accuracy: 0.9213\nEpoch 965/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8613 - accuracy: 0.9101\nEpoch 966/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.9551\nEpoch 967/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8123 - accuracy: 0.9663\nEpoch 968/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.9551\nEpoch 969/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8368 - accuracy: 0.9438\nEpoch 970/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8296 - accuracy: 0.9101\nEpoch 971/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8357 - accuracy: 0.9438\nEpoch 972/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8139 - accuracy: 0.9326\nEpoch 973/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.7753 - accuracy: 0.9663\nEpoch 974/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8051 - accuracy: 0.9438\nEpoch 975/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.9663\nEpoch 976/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.7922 - accuracy: 0.9663\nEpoch 977/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7915 - accuracy: 0.9551\nEpoch 978/1000\n3/3 [==============================] - 0s 26ms/step - loss: 0.7862 - accuracy: 0.9551\nEpoch 979/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8580 - accuracy: 0.9326\nEpoch 980/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8244 - accuracy: 0.9326\nEpoch 981/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8011 - accuracy: 0.9663\nEpoch 982/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7897 - accuracy: 0.9551\nEpoch 983/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9401 - accuracy: 0.9326\nEpoch 984/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.8139 - accuracy: 0.9326\nEpoch 985/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.9213\nEpoch 986/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.7823 - accuracy: 0.9551\nEpoch 987/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.8817 - accuracy: 0.8876\nEpoch 988/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.8989\nEpoch 989/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8783 - accuracy: 0.9326\nEpoch 990/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8519 - accuracy: 0.9326\nEpoch 991/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7964 - accuracy: 0.9326\nEpoch 992/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8501 - accuracy: 0.9101\nEpoch 993/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8236 - accuracy: 0.9326\nEpoch 994/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8174 - accuracy: 0.9326\nEpoch 995/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7793 - accuracy: 0.9438\nEpoch 996/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.8290 - accuracy: 0.9663\nEpoch 997/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7934 - accuracy: 0.9663\nEpoch 998/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8515 - accuracy: 0.9213\nEpoch 999/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8451 - accuracy: 0.8989\nEpoch 1000/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.9438\n1/1 [==============================] - 0s 145ms/step - loss: 0.7181 - accuracy: 0.9565\nAccuracy: 0.95652174949646\n1/1 [==============================] - 0s 79ms/step\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"38f30c14","execution_start":1686315149909,"execution_millis":17526,"deepnote_to_be_reexecuted":false,"cell_id":"643e68ffe4bc489eac3ec102036ee74d","deepnote_cell_type":"code"},"source":"# Build the neural network model\nmodel = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=(len(X_train.columns),)),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(32, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(16, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(3, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=1000, batch_size=32)\n\n# Evaluate the model\n_, accuracy = model.evaluate(X_test, y_test)\nprint('Accuracy:', accuracy)\n\n# Make predictions\npredictions = model.predict(X_test)","execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 503/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8551 - accuracy: 0.7640\nEpoch 504/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.5330 - accuracy: 0.8090\nEpoch 505/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7528\nEpoch 506/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7978\nEpoch 507/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7753\nEpoch 508/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7753\nEpoch 509/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7865\nEpoch 510/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.4995 - accuracy: 0.7865\nEpoch 511/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7640\nEpoch 512/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.8202\nEpoch 513/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7865\nEpoch 514/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8090\nEpoch 515/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7753\nEpoch 516/1000\n3/3 [==============================] - 0s 24ms/step - loss: 0.5533 - accuracy: 0.7753\nEpoch 517/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7528\nEpoch 518/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.7640\nEpoch 519/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7978\nEpoch 520/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8202\nEpoch 521/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8595 - accuracy: 0.7753\nEpoch 522/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7640\nEpoch 523/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.7528\nEpoch 524/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7865\nEpoch 525/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7416\nEpoch 526/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7640\nEpoch 527/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.7640\nEpoch 528/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7753\nEpoch 529/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.7303\nEpoch 530/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7753\nEpoch 531/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7865\nEpoch 532/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.8202\nEpoch 533/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7640\nEpoch 534/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7865\nEpoch 535/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7865\nEpoch 536/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8090\nEpoch 537/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7753\nEpoch 538/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7753\nEpoch 539/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7416\nEpoch 540/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7865\nEpoch 541/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.5474 - accuracy: 0.7753\nEpoch 542/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7753\nEpoch 543/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.7845 - accuracy: 0.7303\nEpoch 544/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7978\nEpoch 545/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7865\nEpoch 546/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7640\nEpoch 547/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7865\nEpoch 548/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7640\nEpoch 549/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7640\nEpoch 550/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8090\nEpoch 551/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7865\nEpoch 552/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.7528\nEpoch 553/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7640\nEpoch 554/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7528\nEpoch 555/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.7416\nEpoch 556/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7445 - accuracy: 0.7978\nEpoch 557/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7640\nEpoch 558/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7753\nEpoch 559/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7865\nEpoch 560/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7865\nEpoch 561/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8090\nEpoch 562/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.7416\nEpoch 563/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7978\nEpoch 564/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7865\nEpoch 565/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7753\nEpoch 566/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7528\nEpoch 567/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7640\nEpoch 568/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7978\nEpoch 569/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.7416\nEpoch 570/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8090\nEpoch 571/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7753\nEpoch 572/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.8090\nEpoch 573/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.8090\nEpoch 574/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7978\nEpoch 575/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7978\nEpoch 576/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7978\nEpoch 577/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7528\nEpoch 578/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8315\nEpoch 579/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.7978\nEpoch 580/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7978\nEpoch 581/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7865\nEpoch 582/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.7640\nEpoch 583/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8202\nEpoch 584/1000\n3/3 [==============================] - 0s 26ms/step - loss: 0.5163 - accuracy: 0.7978\nEpoch 585/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7640\nEpoch 586/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8090\nEpoch 587/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.7528\nEpoch 588/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7978\nEpoch 589/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.7528\nEpoch 590/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7978\nEpoch 591/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7978\nEpoch 592/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8090\nEpoch 593/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.8090\nEpoch 594/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7640\nEpoch 595/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8090\nEpoch 596/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8202\nEpoch 597/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8090\nEpoch 598/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7978\nEpoch 599/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7753\nEpoch 600/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.7753\nEpoch 601/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8090\nEpoch 602/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7978\nEpoch 603/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.5146 - accuracy: 0.7416\nEpoch 604/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7753\nEpoch 605/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7753\nEpoch 606/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7865\nEpoch 607/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7753\nEpoch 608/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7978\nEpoch 609/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7753\nEpoch 610/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7978\nEpoch 611/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7528\nEpoch 612/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.7865\nEpoch 613/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8090\nEpoch 614/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7978\nEpoch 615/1000\n3/3 [==============================] - 0s 26ms/step - loss: 0.5678 - accuracy: 0.8315\nEpoch 616/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7865\nEpoch 617/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7865\nEpoch 618/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8202\nEpoch 619/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.7753\nEpoch 620/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7753\nEpoch 621/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7865\nEpoch 622/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7528\nEpoch 623/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7753\nEpoch 624/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7978\nEpoch 625/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.9235 - accuracy: 0.7753\nEpoch 626/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7978\nEpoch 627/1000\n3/3 [==============================] - 0s 21ms/step - loss: 0.4435 - accuracy: 0.8090\nEpoch 628/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7978\nEpoch 629/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8356 - accuracy: 0.7753\nEpoch 630/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7865\nEpoch 631/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8315\nEpoch 632/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7865\nEpoch 633/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7865\nEpoch 634/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8315\nEpoch 635/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7978\nEpoch 636/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7416\nEpoch 637/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7978\nEpoch 638/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8315\nEpoch 639/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.8090\nEpoch 640/1000\n3/3 [==============================] - 0s 23ms/step - loss: 0.9372 - accuracy: 0.7978\nEpoch 641/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7865\nEpoch 642/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7865\nEpoch 643/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8202\nEpoch 644/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8539\nEpoch 645/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7865\nEpoch 646/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.4693 - accuracy: 0.8090\nEpoch 647/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7640\nEpoch 648/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.8090\nEpoch 649/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7865\nEpoch 650/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.7528\nEpoch 651/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8202\nEpoch 652/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7978\nEpoch 653/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7978\nEpoch 654/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8202\nEpoch 655/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7865\nEpoch 656/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7753\nEpoch 657/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8090\nEpoch 658/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7865\nEpoch 659/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7753\nEpoch 660/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7865\nEpoch 661/1000\n3/3 [==============================] - 0s 2ms/step - loss: 2.4719 - accuracy: 0.7640\nEpoch 662/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7978\nEpoch 663/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7753\nEpoch 664/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7978\nEpoch 665/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7640\nEpoch 666/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8090\nEpoch 667/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.8202\nEpoch 668/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8202\nEpoch 669/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.7838 - accuracy: 0.7753\nEpoch 670/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8315\nEpoch 671/1000\n3/3 [==============================] - 0s 24ms/step - loss: 0.4582 - accuracy: 0.7865\nEpoch 672/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8090\nEpoch 673/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7978\nEpoch 674/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7978\nEpoch 675/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7865\nEpoch 676/1000\n3/3 [==============================] - 0s 2ms/step - loss: 1.1117 - accuracy: 0.7753\nEpoch 677/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7865\nEpoch 678/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7978\nEpoch 679/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7865\nEpoch 680/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7753\nEpoch 681/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8202\nEpoch 682/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7416\nEpoch 683/1000\n3/3 [==============================] - 0s 26ms/step - loss: 0.4184 - accuracy: 0.8427\nEpoch 684/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.8090\nEpoch 685/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7978\nEpoch 686/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.7416\nEpoch 687/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8202\nEpoch 688/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8315\nEpoch 689/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7753\nEpoch 690/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7865\nEpoch 691/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7978\nEpoch 692/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.7978\nEpoch 693/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7978\nEpoch 694/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8090\nEpoch 695/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.8090\nEpoch 696/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7865\nEpoch 697/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8315\nEpoch 698/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7978\nEpoch 699/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8202\nEpoch 700/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7753\nEpoch 701/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.8090\nEpoch 702/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8202\nEpoch 703/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8202\nEpoch 704/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7865\nEpoch 705/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8090\nEpoch 706/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8090\nEpoch 707/1000\n3/3 [==============================] - 0s 24ms/step - loss: 0.5109 - accuracy: 0.7753\nEpoch 708/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8427\nEpoch 709/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8090\nEpoch 710/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7978\nEpoch 711/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7865\nEpoch 712/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8202\nEpoch 713/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.8090\nEpoch 714/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8202\nEpoch 715/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7865\nEpoch 716/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8315\nEpoch 717/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8090\nEpoch 718/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8427\nEpoch 719/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7865\nEpoch 720/1000\n3/3 [==============================] - 0s 22ms/step - loss: 0.5420 - accuracy: 0.7978\nEpoch 721/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7978\nEpoch 722/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8315\nEpoch 723/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8427\nEpoch 724/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7640\nEpoch 725/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8090\nEpoch 726/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8202\nEpoch 727/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7978\nEpoch 728/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8090\nEpoch 729/1000\n3/3 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8315\nEpoch 730/1000\n3/3 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8202\nEpoch 731/1000\n3/3 [==============================] - 0s 16ms/step - loss: 0.3904 - accuracy: 0.8315\nEpoch 732/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8315\nEpoch 733/1000\n3/3 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7978\nEpoch 734/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.7753\nEpoch 735/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7978\nEpoch 736/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.8202\nEpoch 737/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7978\nEpoch 738/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.8427\nEpoch 739/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.8315\nEpoch 740/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7865\nEpoch 741/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8315\nEpoch 742/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8315\nEpoch 743/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.3907 - accuracy: 0.8652\nEpoch 744/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8058 - accuracy: 0.7753\nEpoch 745/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8315\nEpoch 746/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8315\nEpoch 747/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7978\nEpoch 748/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8090\nEpoch 749/1000\n3/3 [==============================] - 0s 23ms/step - loss: 0.5273 - accuracy: 0.8315\nEpoch 750/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8090\nEpoch 751/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7978\nEpoch 752/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7978\nEpoch 753/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.8090\nEpoch 754/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7865\nEpoch 755/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.5629 - accuracy: 0.8090\nEpoch 756/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7865\nEpoch 757/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8202\nEpoch 758/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8202\nEpoch 759/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.8090\nEpoch 760/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8315\nEpoch 761/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8202\nEpoch 762/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7978\nEpoch 763/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8764\nEpoch 764/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8315\nEpoch 765/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7978\nEpoch 766/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8202\nEpoch 767/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8090\nEpoch 768/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8090\nEpoch 769/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7978\nEpoch 770/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8202\nEpoch 771/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.8315\nEpoch 772/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8427\nEpoch 773/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.8202\nEpoch 774/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.8202\nEpoch 775/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8202\nEpoch 776/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.8090\nEpoch 777/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.8090\nEpoch 778/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7978\nEpoch 779/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8315\nEpoch 780/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8202\nEpoch 781/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8315\nEpoch 782/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.8315\nEpoch 783/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8539\nEpoch 784/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8315\nEpoch 785/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7865\nEpoch 786/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8427\nEpoch 787/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7865\nEpoch 788/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7865\nEpoch 789/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.8090\nEpoch 790/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8315\nEpoch 791/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8315\nEpoch 792/1000\n3/3 [==============================] - 0s 24ms/step - loss: 0.5272 - accuracy: 0.8202\nEpoch 793/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8090\nEpoch 794/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8090\nEpoch 795/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8315\nEpoch 796/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8539\nEpoch 797/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8090\nEpoch 798/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.4109 - accuracy: 0.8315\nEpoch 799/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8090\nEpoch 800/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8202\nEpoch 801/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8315\nEpoch 802/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8315\nEpoch 803/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.8202\nEpoch 804/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.4413 - accuracy: 0.8202\nEpoch 805/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8315\nEpoch 806/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8539\nEpoch 807/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8202\nEpoch 808/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8539\nEpoch 809/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8202\nEpoch 810/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.8090\nEpoch 811/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8315\nEpoch 812/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8315\nEpoch 813/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8427\nEpoch 814/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8185 - accuracy: 0.8202\nEpoch 815/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8202\nEpoch 816/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.4002 - accuracy: 0.8427\nEpoch 817/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8427\nEpoch 818/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7640\nEpoch 819/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8427\nEpoch 820/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8539\nEpoch 821/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8090\nEpoch 822/1000\n3/3 [==============================] - 0s 22ms/step - loss: 0.4776 - accuracy: 0.7978\nEpoch 823/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8652\nEpoch 824/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8090\nEpoch 825/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8764\nEpoch 826/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8202\nEpoch 827/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8539\nEpoch 828/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.3373 - accuracy: 0.8764\nEpoch 829/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.8202\nEpoch 830/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8090\nEpoch 831/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.8315\nEpoch 832/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8876\nEpoch 833/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8090\nEpoch 834/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.3885 - accuracy: 0.8090\nEpoch 835/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8202\nEpoch 836/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8202\nEpoch 837/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8202\nEpoch 838/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.8539\nEpoch 839/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8539\nEpoch 840/1000\n3/3 [==============================] - 0s 20ms/step - loss: 0.5805 - accuracy: 0.8876\nEpoch 841/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.8539\nEpoch 842/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.8843 - accuracy: 0.8652\nEpoch 843/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8539\nEpoch 844/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8090\nEpoch 845/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8764\nEpoch 846/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.4024 - accuracy: 0.8090\nEpoch 847/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8315\nEpoch 848/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.8202\nEpoch 849/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8315\nEpoch 850/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8202\nEpoch 851/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8315\nEpoch 852/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8315\nEpoch 853/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8315\nEpoch 854/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8539\nEpoch 855/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8652\nEpoch 856/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8090\nEpoch 857/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8764\nEpoch 858/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.3463 - accuracy: 0.8652\nEpoch 859/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8202\nEpoch 860/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8652\nEpoch 861/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8764\nEpoch 862/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8427\nEpoch 863/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8427\nEpoch 864/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8090\nEpoch 865/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8539\nEpoch 866/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8539\nEpoch 867/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9101\nEpoch 868/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8876\nEpoch 869/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8764\nEpoch 870/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.3024 - accuracy: 0.8652\nEpoch 871/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8652\nEpoch 872/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8652\nEpoch 873/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8876\nEpoch 874/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8652\nEpoch 875/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.9101\nEpoch 876/1000\n3/3 [==============================] - 0s 29ms/step - loss: 0.3129 - accuracy: 0.8764\nEpoch 877/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8652\nEpoch 878/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8652\nEpoch 879/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8427\nEpoch 880/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9101\nEpoch 881/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8427\nEpoch 882/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8652\nEpoch 883/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8876\nEpoch 884/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8427\nEpoch 885/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8539\nEpoch 886/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9101\nEpoch 887/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8764\nEpoch 888/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.5363 - accuracy: 0.8090\nEpoch 889/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8764\nEpoch 890/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8764\nEpoch 891/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.9101\nEpoch 892/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8315\nEpoch 893/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9101\nEpoch 894/1000\n3/3 [==============================] - 0s 25ms/step - loss: 0.6261 - accuracy: 0.8652\nEpoch 895/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.7699 - accuracy: 0.8315\nEpoch 896/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8876\nEpoch 897/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8652\nEpoch 898/1000\n3/3 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8764\nEpoch 899/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8989\nEpoch 900/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8764\nEpoch 901/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.9101\nEpoch 902/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8539\nEpoch 903/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8539\nEpoch 904/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8315\nEpoch 905/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8764\nEpoch 906/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8539\nEpoch 907/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8539\nEpoch 908/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8652\nEpoch 909/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9101\nEpoch 910/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.8652\nEpoch 911/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8764\nEpoch 912/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8539\nEpoch 913/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8876\nEpoch 914/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8539\nEpoch 915/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8764\nEpoch 916/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8652\nEpoch 917/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8764\nEpoch 918/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8539\nEpoch 919/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.8315\nEpoch 920/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.8876\nEpoch 921/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8764\nEpoch 922/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8764\nEpoch 923/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8764\nEpoch 924/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8427\nEpoch 925/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8652\nEpoch 926/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.8989\nEpoch 927/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8652\nEpoch 928/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8989\nEpoch 929/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8652\nEpoch 930/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8652\nEpoch 931/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8539\nEpoch 932/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8539\nEpoch 933/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8764\nEpoch 934/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8539\nEpoch 935/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9101\nEpoch 936/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8764\nEpoch 937/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8764\nEpoch 938/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8539\nEpoch 939/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8764\nEpoch 940/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8876\nEpoch 941/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9101\nEpoch 942/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8876\nEpoch 943/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8764\nEpoch 944/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8652\nEpoch 945/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8652\nEpoch 946/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8427\nEpoch 947/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8876\nEpoch 948/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8427\nEpoch 949/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8652\nEpoch 950/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.3005 - accuracy: 0.8876\nEpoch 951/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9101\nEpoch 952/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8652\nEpoch 953/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8876\nEpoch 954/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8876\nEpoch 955/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8652\nEpoch 956/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.2359 - accuracy: 0.9213\nEpoch 957/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8652\nEpoch 958/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8764\nEpoch 959/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8876\nEpoch 960/1000\n3/3 [==============================] - 0s 2ms/step - loss: 3.8609 - accuracy: 0.8652\nEpoch 961/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8652\nEpoch 962/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8539\nEpoch 963/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.8539\nEpoch 964/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8652\nEpoch 965/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8427\nEpoch 966/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8539\nEpoch 967/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8427\nEpoch 968/1000\n3/3 [==============================] - 0s 28ms/step - loss: 0.4170 - accuracy: 0.8202\nEpoch 969/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8427\nEpoch 970/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8539\nEpoch 971/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8876\nEpoch 972/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8652\nEpoch 973/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8539\nEpoch 974/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.8764\nEpoch 975/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8652\nEpoch 976/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8652\nEpoch 977/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8652\nEpoch 978/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8539\nEpoch 979/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8427\nEpoch 980/1000\n3/3 [==============================] - 0s 29ms/step - loss: 0.3826 - accuracy: 0.8652\nEpoch 981/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9101\nEpoch 982/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8652\nEpoch 983/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8764\nEpoch 984/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8539\nEpoch 985/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8876\nEpoch 986/1000\n3/3 [==============================] - 0s 27ms/step - loss: 0.3066 - accuracy: 0.8652\nEpoch 987/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8764\nEpoch 988/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8539\nEpoch 989/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8652\nEpoch 990/1000\n3/3 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8876\nEpoch 991/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8764\nEpoch 992/1000\n3/3 [==============================] - 0s 23ms/step - loss: 0.2686 - accuracy: 0.8989\nEpoch 993/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8764\nEpoch 994/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.8764\nEpoch 995/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8539\nEpoch 996/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.9101\nEpoch 997/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8652\nEpoch 998/1000\n3/3 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.8764\nEpoch 999/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8876\nEpoch 1000/1000\n3/3 [==============================] - 0s 3ms/step - loss: 0.2252 - accuracy: 0.9213\n1/1 [==============================] - 0s 127ms/step - loss: 0.1634 - accuracy: 0.9130\nAccuracy: 0.9130434989929199\n1/1 [==============================] - 0s 55ms/step\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"8823f48b","execution_start":1686315167469,"execution_millis":1160,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":2},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"daa922ef7cbb4d6295713ce3f9979681","deepnote_cell_type":"code"},"source":"data_axa = pd.read_csv('data - AXA_Edited.csv')\ndata_axa = data_axa.fillna(0)\n\nX_axa = data_axa.drop(['Tanggal', 'Merek', 'Tipe Risiko', 'DPLK'], axis=1)\ny_axa = data_axa['Tipe Risiko']\ny_axa = label_encoder.fit_transform(y_axa)\n\n_, accuracy = model.evaluate(X_axa, y_axa)","execution_count":10,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 0s 5ms/step - loss: 0.1752 - accuracy: 0.9000\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"c6893767","execution_start":1686315167804,"execution_millis":2567,"deepnote_to_be_reexecuted":false,"cell_id":"9b7d8ab0857c48b59bfc474e4b0a4c42","deepnote_cell_type":"code"},"source":"# predicted_labels = np.argmax(predictions, axis=1)\n# predicted_classes = label_encoder.inverse_transform(predicted_labels)\n\n# # Create a DataFrame for recommended products\n# recommended_products = pd.DataFrame({'DPLK': data.loc[X_test.index, 'DPLK'], 'Tipe Risiko': predicted_classes})\n\n# # Group the recommended products by risk level and select the best product for each risk level\n# best_products = recommended_products.groupby('Tipe Risiko').apply(lambda x: x.nlargest(1, 'Nilai Investasi'))\n\n# # Print the recommended products\n# print('Recommended products:')\n# print(best_products)","execution_count":11,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Nilai Investasi'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/indexes/base.py:3081\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mpandas/_libs/index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4554\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4562\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Nilai Investasi'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn [11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m recommended_products \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPLK\u001b[39m\u001b[38;5;124m'\u001b[39m: data\u001b[38;5;241m.\u001b[39mloc[X_test\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPLK\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTipe Risiko\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_classes})\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Group the recommended products by risk level and select the best product for each risk level\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m best_products \u001b[38;5;241m=\u001b[39m \u001b[43mrecommended_products\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTipe Risiko\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNilai Investasi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Print the recommended products\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecommended products:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:894\u001b[0m, in \u001b[0;36mBaseGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 894\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m    902\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m group_selection_context(\u001b[38;5;28mself\u001b[39m):\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:928\u001b[0m, in \u001b[0;36mBaseGroupBy._python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28mself\u001b[39m, f: F, data: FrameOrSeriesUnion\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeriesUnion:\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 928\u001b[0m     keys, values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_applied_output(\n\u001b[1;32m    931\u001b[0m         keys, values, not_indexed_same\u001b[38;5;241m=\u001b[39mmutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n\u001b[1;32m    932\u001b[0m     )\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/groupby/ops.py:238\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    237\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 238\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    240\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","Cell \u001b[0;32mIn [11], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m recommended_products \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPLK\u001b[39m\u001b[38;5;124m'\u001b[39m: data\u001b[38;5;241m.\u001b[39mloc[X_test\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPLK\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTipe Risiko\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_classes})\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Group the recommended products by risk level and select the best product for each risk level\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m best_products \u001b[38;5;241m=\u001b[39m recommended_products\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTipe Risiko\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNilai Investasi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Print the recommended products\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecommended products:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/frame.py:5797\u001b[0m, in \u001b[0;36mDataFrame.nlargest\u001b[0;34m(self, n, columns, keep)\u001b[0m\n\u001b[1;32m   5690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnlargest\u001b[39m(\u001b[38;5;28mself\u001b[39m, n, columns, keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   5691\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5692\u001b[0m \u001b[38;5;124;03m    Return the first `n` rows ordered by `columns` in descending order.\u001b[39;00m\n\u001b[1;32m   5693\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5795\u001b[0m \u001b[38;5;124;03m    Brunei      434000    12128      BN\u001b[39;00m\n\u001b[1;32m   5796\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelectNFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/algorithms.py:1183\u001b[0m, in \u001b[0;36mSelectN.nlargest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnlargest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnlargest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/algorithms.py:1295\u001b[0m, in \u001b[0;36mSelectNFrame.compute\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m   1292\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m-> 1295\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_valid_dtype_n_method(dtype):\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(column)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot use method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with this dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1300\u001b[0m         )\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/frame.py:3024\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3024\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3026\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/indexes/base.py:3083\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3082\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3083\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3086\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tolerance(tolerance, np\u001b[38;5;241m.\u001b[39masarray(key))\n","\u001b[0;31mKeyError\u001b[0m: 'Nilai Investasi'"]}]},{"cell_type":"code","metadata":{"source_hash":"a18b60d","execution_start":1686130098240,"execution_millis":18,"deepnote_to_be_reexecuted":true,"cell_id":"e1fa6cb8ca424527884049d46c5a315d","deepnote_cell_type":"code"},"source":"model.save('model.h5')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"c998216f","execution_start":1686315264341,"execution_millis":103,"deepnote_to_be_reexecuted":false,"cell_id":"aa839409f0b2444ca840a5d97eb9f010","deepnote_cell_type":"code"},"source":"x_input = np.array([100, 0, 0, 1.38, 2.39, 0.14, -0.81, 23.64, 17.07, 0])\nprint(x_input.reshape((1, 10)))\npredict = model.predict(x_input.reshape((1, 10)))\nprint(np.argmax(predict))","execution_count":12,"outputs":[{"name":"stdout","text":"[[100.     0.     0.     1.38   2.39   0.14  -0.81  23.64  17.07   0.  ]]\n1/1 [==============================] - 0s 60ms/step\n0\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"3272edd8","execution_start":1686315266071,"execution_millis":197,"deepnote_to_be_reexecuted":false,"cell_id":"c3277b75f22d46389bcfd01a6779f111","deepnote_cell_type":"code"},"source":"import tensorflowjs as tfjs\ntfjs.converters.save_keras_model(model, './')","execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=1dcfcf18-1dc4-4867-9375-d0be4bf5355a' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"f95044d651b940a0ae71c5130f06dae0","deepnote_persisted_session":{"createdAt":"2023-06-09T13:16:40.945Z"},"deepnote_execution_queue":[]}}